# Story 10.3: Google Drive Folder Monitoring

**Story ID:** 10.3
**Epic:** E10 — Email & Document Integration
**Assigned to:** @dev
**Sprint:** Sprint 8 (Week 12)
**Status:** Ready for Review
**Estimation:** 8 story points (3-4 days)
**Review:** @devops (Gage) — infrastructure, OAuth setup, scheduling

---

## Summary

Implement automatic monitoring of Google Drive folders for new project documents. Each project can be configured with a Google Drive folder ID. The system periodically polls the folder for new PDF and DOCX files, downloads them, extracts text, and creates `Source` records (status: pending) in the Ingestion Approval queue. This automates the document discovery step — instead of manually uploading, documents placed in a shared Drive folder are automatically detected and queued for processing.

---

## Acceptance Criteria

### Google Drive API Integration
- [x] Google Drive API OAuth2 authentication configured (service account recommended for server-to-server)
- [x] OAuth credentials stored securely in environment variables:
  - [x] `GOOGLE_DRIVE_SERVICE_ACCOUNT_KEY` — path to service account JSON key file
  - [x] `GOOGLE_DRIVE_ENABLED` — boolean flag to enable/disable monitoring (default: false)
- [x] Drive API client initialized at startup when enabled
- [x] Scopes: `https://www.googleapis.com/auth/drive.readonly`

### Folder Configuration (Per Project)
- [x] New field on `Project` model: `drive_folder_id: string?`
- [x] `PATCH /api/projects/{id}` accepts `drive_folder_id` to configure monitoring
- [x] Project Form (Story 6.2) shows optional "Google Drive Folder ID" text input
- [x] Validation: verify folder is accessible with configured credentials on save
- [x] Admin-only configuration

### Polling Mechanism
- [x] Background polling job runs on a configurable schedule
- [x] Polling frequency configurable via `DRIVE_POLL_INTERVAL_MINUTES` env variable (default: 60)
- [x] Uses APScheduler (consistent with Gmail poller in Story 7.4)
- [x] Job queries all projects with non-null `drive_folder_id`
- [x] For each project folder:
  - [x] List files modified/created since last poll timestamp
  - [x] Filter: only `.pdf` and `.docx` files
  - [x] Skip files already processed (deduplication by Drive file ID)

### File Processing
- [x] For each new file discovered:
  - [x] Download file content from Google Drive API
  - [x] Extract text using `DocumentProcessor` (Story 10.2)
  - [x] Generate AI one-line summary from first 2000 chars
  - [x] Create `Source` record:
    - [x] `source_type='document'`
    - [x] `ingestion_status='pending'`
    - [x] `title` = file name
    - [x] `raw_content` = extracted text
    - [x] `file_url` = Google Drive file URL
    - [x] `file_type` = "pdf" or "docx"
    - [x] `file_size` = file size in bytes
    - [x] `drive_folder_id` = originating folder ID
    - [x] `ai_summary` = one-line summary
  - [x] Store file locally in `uploads/documents/{project_id}/{source_id}.{ext}`

### Deduplication
- [x] Track processed Drive file IDs to avoid re-processing
- [x] New column on `Source`: `drive_file_id: string? (UNIQUE where not null)`
- [x] Before creating Source, check if `drive_file_id` already exists
- [x] Skip silently if duplicate (log at debug level)

### Error Handling
- [x] Drive API authentication failure: log error, disable polling for that cycle, retry next cycle
- [x] Folder not found / access denied: log warning, skip project
- [x] File download failure: log error, skip file, continue with others
- [x] Text extraction failure: create Source with empty `raw_content`, mark for manual review
- [x] Rate limiting: respect Google Drive API quotas (1000 queries/100 seconds per user)
- [x] Network timeout: 30-second timeout per API call

### Monitoring & Logging
- [x] Log each poll cycle: "Polling {N} project folders"
- [x] Log each new file discovered: "Found new file: {filename} in project {project_name}"
- [x] Log each Source created: "Created source {source_id} from Drive file {file_id}"
- [x] Track last successful poll timestamp per project (stored in project metadata or separate table)

---

## Tasks

### Task 1: Google Drive API Client Setup (0.5 days)

1. **Create `decision-log-backend/app/services/drive_client.py`**
   ```python
   import os
   from google.oauth2.service_account import Credentials
   from googleapiclient.discovery import build
   from googleapiclient.http import MediaIoBaseDownload
   import io

   SCOPES = ['https://www.googleapis.com/auth/drive.readonly']

   class DriveClient:
       def __init__(self):
           key_path = os.getenv('GOOGLE_DRIVE_SERVICE_ACCOUNT_KEY')
           if not key_path:
               raise ValueError("GOOGLE_DRIVE_SERVICE_ACCOUNT_KEY not configured")
           credentials = Credentials.from_service_account_file(key_path, scopes=SCOPES)
           self.service = build('drive', 'v3', credentials=credentials)

       def list_new_files(self, folder_id: str, since: str, file_types: list[str] = None) -> list[dict]:
           """List files in folder modified after `since` timestamp."""
           query = f"'{folder_id}' in parents and trashed = false"
           if since:
               query += f" and modifiedTime > '{since}'"
           if file_types:
               mime_queries = []
               for ft in file_types:
                   if ft == 'pdf':
                       mime_queries.append("mimeType = 'application/pdf'")
                   elif ft == 'docx':
                       mime_queries.append("mimeType = 'application/vnd.openxmlformats-officedocument.wordprocessingml.document'")
               if mime_queries:
                   query += f" and ({' or '.join(mime_queries)})"

           results = self.service.files().list(
               q=query,
               fields="files(id, name, mimeType, size, modifiedTime, webViewLink)",
               orderBy="modifiedTime desc",
               pageSize=100,
           ).execute()
           return results.get('files', [])

       def download_file(self, file_id: str) -> bytes:
           """Download file content."""
           request = self.service.files().get_media(fileId=file_id)
           buffer = io.BytesIO()
           downloader = MediaIoBaseDownload(buffer, request)
           done = False
           while not done:
               _, done = downloader.next_chunk()
           return buffer.getvalue()

       def verify_folder_access(self, folder_id: str) -> bool:
           """Check if the service account can access the folder."""
           try:
               self.service.files().get(fileId=folder_id, fields="id,name").execute()
               return True
           except Exception:
               return False
   ```

### Task 2: Polling Job (1 day)

1. **Create `decision-log-backend/app/services/drive_monitor.py`**
   ```python
   import logging
   from datetime import datetime
   from app.services.drive_client import DriveClient
   from app.services.document_processor import DocumentProcessor
   from app.database.models import Source, Project

   logger = logging.getLogger(__name__)

   class DriveMonitor:
       def __init__(self, db_session):
           self.db = db_session
           self.drive = DriveClient()
           self.processor = DocumentProcessor()

       async def poll_all_projects(self):
           """Poll all projects with configured Drive folders."""
           projects = self.db.query(Project).filter(
               Project.drive_folder_id.isnot(None)
           ).all()
           logger.info(f"Polling {len(projects)} project folders")

           for project in projects:
               try:
                   await self.poll_project(project)
               except Exception as e:
                   logger.error(f"Failed to poll project {project.id}: {e}")

       async def poll_project(self, project: Project):
           """Poll a single project's Drive folder for new files."""
           last_poll = project.last_drive_poll or "2000-01-01T00:00:00Z"
           files = self.drive.list_new_files(
               folder_id=project.drive_folder_id,
               since=last_poll,
               file_types=['pdf', 'docx'],
           )

           for file_info in files:
               # Deduplication check
               existing = self.db.query(Source).filter(
                   Source.drive_file_id == file_info['id']
               ).first()
               if existing:
                   continue

               await self._process_drive_file(project, file_info)

           # Update last poll timestamp
           project.last_drive_poll = datetime.utcnow().isoformat()
           self.db.commit()

       async def _process_drive_file(self, project, file_info):
           """Download, extract text, and create Source record."""
           logger.info(f"Found new file: {file_info['name']} in project {project.title}")

           content = self.drive.download_file(file_info['id'])
           ext = 'pdf' if 'pdf' in file_info['mimeType'] else 'docx'
           raw_text = self.processor.extract_text(content, ext)

           # Save file locally
           file_path = f"uploads/documents/{project.id}/{file_info['id']}.{ext}"
           os.makedirs(os.path.dirname(file_path), exist_ok=True)
           with open(file_path, "wb") as f:
               f.write(content)

           # Generate summary
           summary = await generate_summary(raw_text[:2000]) if raw_text else None

           source = Source(
               project_id=project.id,
               source_type="document",
               title=file_info['name'],
               raw_content=raw_text or "",
               file_url=file_info.get('webViewLink', file_path),
               file_type=ext,
               file_size=int(file_info.get('size', 0)),
               drive_file_id=file_info['id'],
               ai_summary=summary,
               ingestion_status="pending",
           )
           self.db.add(source)
           self.db.commit()
           logger.info(f"Created source {source.id} from Drive file {file_info['id']}")
   ```

### Task 3: Schedule Polling Job (0.25 days)

1. **Modify `decision-log-backend/app/main.py`** or scheduler config
   ```python
   from apscheduler.schedulers.asyncio import AsyncIOScheduler
   import os

   scheduler = AsyncIOScheduler()

   if os.getenv("GOOGLE_DRIVE_ENABLED", "false").lower() == "true":
       interval = int(os.getenv("DRIVE_POLL_INTERVAL_MINUTES", "60"))
       scheduler.add_job(
           drive_monitor.poll_all_projects,
           "interval",
           minutes=interval,
           id="drive_monitor",
       )
       scheduler.start()
   ```

### Task 4: Database Updates (0.25 days)

1. **Add fields to `Project` model:**
   - `drive_folder_id: String, nullable`
   - `last_drive_poll: DateTime, nullable`

2. **Add field to `Source` model:**
   - `drive_file_id: String, nullable, unique`

3. **Create migration script**

### Task 5: Update Project Form (0.25 days)

1. **Modify `src/components/organisms/ProjectForm.tsx`** (Story 6.2)
   - Add optional "Google Drive Folder ID" text input in settings section
   - Help text: "Paste the folder ID from Google Drive to enable automatic document monitoring"
   - Validation: verify access on save (async call to backend validation endpoint)

### Task 6: Write Tests (1 day)

1. **Create `decision-log-backend/tests/test_drive_monitor.py`**
   - Mock Drive API responses
   - New files create Source records
   - Duplicate files are skipped (by drive_file_id)
   - Folder access verification works
   - Only PDF/DOCX files are processed
   - Last poll timestamp updated after successful poll
   - Error handling: inaccessible folder skipped
   - Error handling: download failure skips file

2. **Create `decision-log-backend/tests/test_drive_client.py`**
   - File listing with date filter
   - File download returns bytes
   - Folder access verification

---

## Dev Notes

### Google Drive API Authentication

**Recommended: Service Account**
- No user consent flow needed (server-to-server)
- Service account email shared as viewer on project folders
- JSON key file stored securely (not in repo)

**Alternative: OAuth2 User Consent**
- Requires user login flow
- More complex but grants access to user's personal Drive
- Deferred to V3 if needed

### Folder ID Extraction

Users need to paste the folder ID from Drive. The ID is found in the folder URL:
```
https://drive.google.com/drive/folders/1a2b3c4d5e6f7g8h9i0j
                                       ^ This is the folder ID
```

### Rate Limiting

Google Drive API quotas:
- 1,000 queries per 100 seconds per user
- 10 queries per second per user
- Our polling is well within limits (one `list` + N `download` calls per project per hour)

### Polling vs Webhooks

| Approach | Pros | Cons |
|----------|------|------|
| **Polling (chosen)** | Simpler, no public endpoint needed | Delay between file upload and detection |
| Drive Push Notifications | Real-time detection | Requires public webhook URL, complex setup |

Polling is appropriate for V1 — 60-minute default interval is acceptable for document discovery.

### New Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `GOOGLE_DRIVE_ENABLED` | `false` | Enable Drive monitoring |
| `GOOGLE_DRIVE_SERVICE_ACCOUNT_KEY` | — | Path to service account JSON key |
| `DRIVE_POLL_INTERVAL_MINUTES` | `60` | Polling frequency |

---

## File List

**New Files:**
- `decision-log-backend/app/services/drive_client.py` — Google Drive API client
- `decision-log-backend/app/services/drive_monitor.py` — Polling monitor service
- `decision-log-backend/app/services/document_processor.py` — Text extraction (PDF/DOCX)
- `decision-log-backend/app/scheduler.py` — APScheduler background job manager
- `decision-log-backend/tests/unit/test_drive_monitor.py` — Monitor unit tests (9 tests)
- `decision-log-backend/tests/unit/test_drive_client.py` — Client unit tests (10 tests)
- `decision-log-frontend/src/components/organisms/ProjectForm.tsx` — Project create/edit form
- `decision-log-frontend/src/tests/components/ProjectForm.test.tsx` — Form tests (13 tests)

**Modified Files:**
- `decision-log-backend/app/database/models.py` — Add drive_folder_id, last_drive_poll (Project); drive_file_id (Source)
- `decision-log-backend/app/config.py` — Add Google Drive config fields + is_drive_configured()
- `decision-log-backend/app/main.py` — Integrate scheduler startup/shutdown in lifespan
- `decision-log-backend/app/api/routes/projects.py` — Add PATCH endpoint with ProjectUpdate model
- `decision-log-backend/requirements.txt` — Add google-api-python-client, google-auth, apscheduler, pdfplumber, python-docx
- `decision-log-frontend/src/types/project.ts` — Add drive_folder_id, project_type to Project interface

---

## Testing Strategy

### Unit Tests
```
- [x] Drive client MIME type mappings correct
- [x] Drive client raises without credentials
- [x] Drive client initializes with valid credentials
- [x] Drive client lists files in folder
- [x] Drive client returns files from API response
- [x] Drive client handles empty response
- [x] Drive client verifies folder access success
- [x] Drive client verifies folder access failure
- [x] Monitor creates Source records for new files
- [x] Monitor skips duplicate files (by drive_file_id)
- [x] Monitor updates last_drive_poll timestamp
- [x] Monitor queries only configured projects
- [x] Monitor handles download failure gracefully
- [x] Monitor handles text extraction failure gracefully
- [x] Monitor continues past project-level errors
- [x] Monitor passes since timestamp correctly
- [x] Monitor handles first poll (no since)
- [x] ProjectForm renders Drive Folder ID field
- [x] ProjectForm submits drive_folder_id
- [x] Polling job disabled when GOOGLE_DRIVE_ENABLED=false
```

### Integration Tests (Manual)
- Configure test folder -> add file -> wait for poll -> verify Source created -> approve -> verify items extracted

### Coverage Target: 80%+

---

## Change Log

| Date | Change |
|------|--------|
| 2026-02-20 | Created story |
| 2026-02-28 | Implemented all tasks: DriveClient, DriveMonitor, scheduler, DB model updates, config, ProjectForm, PATCH endpoint, tests (19 backend + 13 frontend, all passing) |

---

**Related Stories:** 10.2 (document processing pipeline), 7.1 (Source entity), 6.2 (Project Form for config)
**Blocked By:** 10.2 (DocumentProcessor must exist for text extraction), 7.1 (Source entity)
**Blocks:** None (final E10 story)
