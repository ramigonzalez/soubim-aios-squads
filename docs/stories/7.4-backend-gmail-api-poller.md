# Story 7.4: Backend — Gmail API Poller (Email Ingestion)

**Story ID:** 7.4
**Epic:** E7 — Multi-Source Ingestion Pipeline
**Assigned to:** @dev
**Sprint:** Sprint 5 (Week 9-10, Phase 4)
**Status:** Draft
**Estimation:** 8 story points (3 days)
**Review:** @devops (Gage) — infrastructure review
**Blocked By:** 5.1 (sources table schema), 7.1 (Source entity & ingestion queue)
**Blocks:** 10.1 (Email extraction pipeline uses polled email Source records)
**Related:** 7.2 (polled emails surface in Ingestion Approval page)

---

## Summary

Build a scheduled background job that authenticates with Gmail via OAuth2, polls for project-related emails on a configurable interval, and creates `Source` records (status: `pending`) for each new email found. Emails are matched to projects via Gmail labels or folder rules, deduplicated by thread ID + message ID, and enriched with a Claude-generated one-line AI summary before entering the ingestion approval queue. The poller runs via APScheduler and respects Gmail API quotas using exponential backoff.

**Critical:** The poller must never create duplicate Source records. Deduplication is the single most important correctness guarantee for this story.

---

## Acceptance Criteria

### OAuth2 Authentication (Gmail API)
- [ ] Google OAuth2 credentials loaded from environment variables (`GMAIL_CLIENT_ID`, `GMAIL_CLIENT_SECRET`, `GMAIL_REFRESH_TOKEN` or `GMAIL_SERVICE_ACCOUNT_JSON`)
- [ ] `GmailAuthService` handles token refresh automatically (access tokens expire after 1 hour)
- [ ] Service account flow supported for server-to-server auth (no user interaction)
- [ ] User consent OAuth2 flow documented as alternative in Dev Notes (for multi-tenant future)
- [ ] Auth failure logs error and skips polling cycle — does NOT crash the background scheduler

### Polling Configuration
- [ ] `GMAIL_POLL_INTERVAL_MINUTES` environment variable controls poll frequency (default: `30`)
- [ ] `GMAIL_LABEL_FILTER` environment variable specifies Gmail label(s) to match (default: `""` — matches all unread)
- [ ] `GMAIL_MAX_RESULTS_PER_POLL` environment variable caps emails fetched per cycle (default: `50`)
- [ ] All three env vars added to `decision-log-backend/app/config.py` with proper defaults
- [ ] Polling interval validated: minimum `5` minutes enforced (guards against API quota exhaustion)
- [ ] Configuration logged at scheduler startup (interval, label filter, max results)

### Email Matching & Project Association
- [ ] `EmailMatcherService` determines which project a polled email belongs to
- [ ] Matching strategy: Gmail label name matches project slug or project-specific label (e.g., `project/skyline-tower`)
- [ ] Fallback matching: email subject or sender domain matched against project metadata
- [ ] Unmatched emails logged at `WARNING` level and skipped (not stored as Source records)
- [ ] Matched project ID stored on Source record

### Source Record Creation
- [ ] For each new (non-duplicate) email: one `Source` record created with:
  - [ ] `source_type = 'email'`
  - [ ] `ingestion_status = 'pending'`
  - [ ] `raw_content` = decoded plain-text email body (HTML stripped)
  - [ ] `title` = email subject line
  - [ ] `occurred_at` = email sent date (parsed from Gmail `Date` header)
  - [ ] `email_from` = sender address
  - [ ] `email_to` = list of primary recipients (JSONB array)
  - [ ] `email_cc` = list of CC recipients (JSONB array)
  - [ ] `email_thread_id` = Gmail thread ID
  - [ ] `project_id` = matched project UUID
- [ ] Source record saved to `sources` table (from Story 5.1 migration)
- [ ] Message ID stored in `webhook_id` field for deduplication lookup

### AI One-Line Summary
- [ ] Claude 3.5 Sonnet called for each new email Source record to generate a one-line summary
- [ ] Summary stored in `ai_summary` field on Source record
- [ ] Summary prompt: `"Summarize this email in one sentence for a project manager: {email_body}"`
- [ ] Summary capped at 150 characters; truncated with ellipsis if Claude returns more
- [ ] AI summary failure does NOT block Source record creation — `ai_summary` left null on error
- [ ] AI summary errors logged at `WARNING` level with email subject for traceability

### Deduplication
- [ ] Before creating a Source record, check for existing record with same `email_thread_id` AND `webhook_id` (message ID)
- [ ] If duplicate found: skip silently (log at `DEBUG` level)
- [ ] Thread-level deduplication only (distinct messages in same thread ARE stored separately)
- [ ] Deduplication check runs inside a database transaction to prevent race conditions

### Rate Limiting & Quota Management
- [ ] Gmail API calls wrapped in exponential backoff retry logic
- [ ] Retry schedule: wait `2^attempt` seconds (1s, 2s, 4s, 8s, 16s), max 5 retries
- [ ] `googleapiclient.errors.HttpError` with status `429` (quota exceeded) triggers backoff
- [ ] `googleapiclient.errors.HttpError` with status `500`/`503` (transient) triggers backoff
- [ ] After max retries exhausted: log `ERROR` and skip current polling cycle
- [ ] Total Gmail API calls per poll cycle logged for monitoring

### Background Scheduler
- [ ] APScheduler `BackgroundScheduler` initialized in `decision-log-backend/app/scheduler.py`
- [ ] Gmail polling job registered with `IntervalTrigger` using `GMAIL_POLL_INTERVAL_MINUTES`
- [ ] Scheduler started on FastAPI `startup` event and shut down on `shutdown` event
- [ ] Job runs are non-overlapping: if previous poll cycle still running, new trigger skipped
- [ ] Scheduler state (next run time, last run time) accessible via `GET /api/admin/scheduler/status` (admin only)

### Integration Verification
- [ ] IV1: Polled emails appear in Ingestion Approval page (`GET /api/ingestion` returns them as pending Sources)
- [ ] IV2: Approved email Sources trigger item extraction pipeline (Story 10.1 consumes these records)
- [ ] IV3: Email Source rows in Ingestion Approval display: Email ID, Project, Date, Subject, From, To/CC count, AI Summary, Thread link

---

## Tasks

### Task 1: Add Gmail Config to `app/config.py` (0.25 days)

1. **Update `decision-log-backend/app/config.py`**

   ```python
   """Application configuration using Pydantic Settings."""

   from pydantic_settings import BaseSettings
   from typing import Optional, List


   class Settings(BaseSettings):
       """Application settings loaded from environment variables."""

       # Database
       database_url: str

       # JWT Configuration
       jwt_secret_key: str
       jwt_algorithm: str = "HS256"
       jwt_expiration_minutes: int = 10080  # 7 days

       # Anthropic API
       anthropic_api_key: str

       # Tactiq Webhook
       tactiq_webhook_secret: str

       # Sentry
       sentry_dsn: Optional[str] = None

       # Environment
       environment: str = "development"
       debug: bool = True
       demo_mode: bool = False

       # CORS
       cors_origins: List[str] = ["http://localhost:5173", "http://localhost:3000"]

       # --- Gmail API Poller (Story 7.4) ---
       # OAuth2 credentials — use service account for server-to-server auth
       gmail_client_id: Optional[str] = None
       gmail_client_secret: Optional[str] = None
       gmail_refresh_token: Optional[str] = None
       # Alternative: service account JSON (base64-encoded)
       gmail_service_account_json: Optional[str] = None

       # Polling configuration
       gmail_poll_interval_minutes: int = 30  # How often to poll Gmail
       gmail_label_filter: str = ""  # Gmail label to filter (empty = all unread)
       gmail_max_results_per_poll: int = 50  # Max emails fetched per cycle

       class Config:
           env_file = ".env.development"
           case_sensitive = False

       def is_gmail_configured(self) -> bool:
           """Return True if Gmail API credentials are present."""
           has_oauth2 = all([
               self.gmail_client_id,
               self.gmail_client_secret,
               self.gmail_refresh_token,
           ])
           has_service_account = self.gmail_service_account_json is not None
           return has_oauth2 or has_service_account
   ```

2. **Add Gmail credentials to `decision-log-backend/.env.example`** (for documentation):

   ```env
   # Gmail API Poller (Story 7.4)
   GMAIL_CLIENT_ID=your-google-oauth2-client-id.apps.googleusercontent.com
   GMAIL_CLIENT_SECRET=your-google-oauth2-client-secret
   GMAIL_REFRESH_TOKEN=your-long-lived-refresh-token
   # OR for service account auth:
   # GMAIL_SERVICE_ACCOUNT_JSON=base64-encoded-service-account-json

   GMAIL_POLL_INTERVAL_MINUTES=30
   GMAIL_LABEL_FILTER=soubim-projects
   GMAIL_MAX_RESULTS_PER_POLL=50
   ```

### Task 2: Create Gmail Auth Service (0.5 days)

1. **Create `decision-log-backend/app/services/gmail_auth.py`**

   ```python
   """Gmail OAuth2 authentication service."""

   import base64
   import json
   import logging
   from typing import Optional

   from google.oauth2 import service_account
   from google.oauth2.credentials import Credentials
   from google.auth.transport.requests import Request
   from google_auth_oauthlib.flow import InstalledAppFlow
   from googleapiclient.discovery import build
   from googleapiclient.errors import HttpError

   from app.config import settings

   logger = logging.getLogger(__name__)

   GMAIL_SCOPES = ["https://www.googleapis.com/auth/gmail.readonly"]


   class GmailAuthService:
       """Handles Gmail API authentication and token refresh."""

       def __init__(self):
           self._credentials: Optional[Credentials] = None
           self._service = None

       def get_service(self):
           """
           Return an authenticated Gmail API service client.

           Refreshes credentials automatically if expired.

           Returns:
               googleapiclient Resource object for Gmail API v1

           Raises:
               RuntimeError: If Gmail credentials are not configured
               google.auth.exceptions.RefreshError: If token refresh fails
           """
           if not settings.is_gmail_configured():
               raise RuntimeError(
                   "Gmail API credentials not configured. "
                   "Set GMAIL_CLIENT_ID + GMAIL_CLIENT_SECRET + GMAIL_REFRESH_TOKEN "
                   "or GMAIL_SERVICE_ACCOUNT_JSON in environment."
               )

           credentials = self._get_or_refresh_credentials()
           self._service = build("gmail", "v1", credentials=credentials, cache_discovery=False)
           return self._service

       def _get_or_refresh_credentials(self) -> Credentials:
           """Build or refresh OAuth2 credentials."""
           # Service account path (preferred for server-to-server)
           if settings.gmail_service_account_json:
               return self._build_service_account_credentials()

           # OAuth2 user credentials path
           return self._build_oauth2_credentials()

       def _build_service_account_credentials(self) -> Credentials:
           """Build credentials from base64-encoded service account JSON."""
           try:
               json_bytes = base64.b64decode(settings.gmail_service_account_json)
               service_account_info = json.loads(json_bytes)
               credentials = service_account.Credentials.from_service_account_info(
                   service_account_info,
                   scopes=GMAIL_SCOPES,
               )
               logger.debug("Gmail: Using service account credentials")
               return credentials
           except Exception as e:
               logger.error(f"Gmail: Failed to build service account credentials: {e}")
               raise

       def _build_oauth2_credentials(self) -> Credentials:
           """Build OAuth2 user credentials, refreshing if expired."""
           if self._credentials and self._credentials.valid:
               return self._credentials

           credentials = Credentials(
               token=None,
               refresh_token=settings.gmail_refresh_token,
               client_id=settings.gmail_client_id,
               client_secret=settings.gmail_client_secret,
               token_uri="https://oauth2.googleapis.com/token",
           )

           if not credentials.valid:
               logger.info("Gmail: Refreshing OAuth2 access token")
               credentials.refresh(Request())

           self._credentials = credentials
           logger.debug("Gmail: OAuth2 credentials ready")
           return credentials


   # Singleton instance
   gmail_auth_service = GmailAuthService()
   ```

### Task 3: Create Email Matcher Service (0.5 days)

1. **Create `decision-log-backend/app/services/email_matcher.py`**

   ```python
   """Email-to-project matching service."""

   import logging
   import re
   from typing import Optional

   from sqlalchemy.orm import Session

   from app.database.models import Project
   from app.config import settings

   logger = logging.getLogger(__name__)


   class EmailMatcherService:
       """
       Determines which project a Gmail email belongs to.

       Matching priority:
       1. Gmail label matches project slug (e.g., label "project/skyline-tower")
       2. Gmail label matches project name (case-insensitive)
       3. Email subject contains project name
       4. No match — email skipped
       """

       def match_project(
           self,
           db: Session,
           gmail_labels: list[str],
           email_subject: str,
           email_from: str,
       ) -> Optional[str]:
           """
           Find the project UUID that this email belongs to.

           Args:
               db: Database session
               gmail_labels: List of Gmail label names applied to the message
               email_subject: Email subject line
               email_from: Sender email address

           Returns:
               Project UUID string if matched, None if no match found
           """
           # Fetch all active projects for matching
           projects = db.query(Project).filter(Project.archived_at.is_(None)).all()

           if not projects:
               logger.warning("EmailMatcher: No active projects found for matching")
               return None

           # Strategy 1: Label matches project slug (e.g., "project/skyline-tower")
           for label in gmail_labels:
               matched_id = self._match_label_to_project(label, projects)
               if matched_id:
                   logger.info(f"EmailMatcher: Matched via label '{label}' to project {matched_id}")
                   return matched_id

           # Strategy 2: Subject line contains project name
           subject_lower = email_subject.lower()
           for project in projects:
               if project.title and project.title.lower() in subject_lower:
                   logger.info(
                       f"EmailMatcher: Matched via subject to project '{project.title}' ({project.id})"
                   )
                   return str(project.id)

           # No match found
           logger.warning(
               f"EmailMatcher: No project match for email '{email_subject}' from {email_from}. "
               f"Labels: {gmail_labels}. Skipping."
           )
           return None

       def _match_label_to_project(self, label: str, projects: list) -> Optional[str]:
           """
           Check if a Gmail label matches any project.

           Handles patterns:
           - "project/skyline-tower" → slug match
           - "Skyline Tower" → name match
           - "soubim/skyline-tower" → prefixed slug match
           """
           label_lower = label.lower()

           # Strip common prefixes
           for prefix in ["project/", "soubim/", "proj/"]:
               if label_lower.startswith(prefix):
                   label_lower = label_lower[len(prefix):]
                   break

           # Normalize label: replace hyphens/underscores with spaces
           label_normalized = re.sub(r"[-_]", " ", label_lower).strip()

           for project in projects:
               if not project.title:
                   continue

               project_title_lower = project.title.lower()
               project_slug = re.sub(r"[-_\s]+", " ", project_title_lower).strip()

               if label_normalized == project_slug or label_lower == project_title_lower:
                   return str(project.id)

           return None


   # Singleton instance
   email_matcher_service = EmailMatcherService()
   ```

### Task 4: Create Gmail Poller Service (1 day)

1. **Create `decision-log-backend/app/services/gmail_poller.py`**

   ```python
   """Gmail API polling service for email ingestion."""

   import base64
   import logging
   import time
   from datetime import datetime, timezone
   from email import message_from_bytes
   from email.utils import parseaddr, parsedate_to_datetime
   from html.parser import HTMLParser
   from typing import Optional
   from uuid import uuid4

   from anthropic import Anthropic
   from googleapiclient.errors import HttpError
   from sqlalchemy.orm import Session

   from app.config import settings
   from app.database.models import Source
   from app.database.session import SessionLocal
   from app.services.email_matcher import email_matcher_service
   from app.services.gmail_auth import gmail_auth_service

   logger = logging.getLogger(__name__)

   # Gmail API quota retry config
   MAX_RETRIES = 5
   RETRY_BASE_SECONDS = 1  # Doubles each attempt: 1, 2, 4, 8, 16


   class HTMLStripper(HTMLParser):
       """Minimal HTML-to-plaintext converter for email body cleaning."""

       def __init__(self):
           super().__init__()
           self.reset()
           self.fed = []

       def handle_data(self, d):
           self.fed.append(d)

       def get_data(self):
           return " ".join(self.fed)


   def strip_html(html_body: str) -> str:
       """Strip HTML tags and return plain text."""
       stripper = HTMLStripper()
       stripper.feed(html_body)
       return stripper.get_data().strip()


   class GmailPollerService:
       """
       Polls Gmail for project-related emails and creates Source records.

       Responsibilities:
       - Authenticate with Gmail API (delegated to GmailAuthService)
       - Fetch new emails matching configured label filter
       - Match emails to projects (delegated to EmailMatcherService)
       - Deduplicate by thread ID + message ID
       - Create Source records with status='pending'
       - Generate AI one-line summaries via Claude
       - Respect Gmail API quotas with exponential backoff
       """

       def __init__(self):
           self.anthropic = Anthropic(api_key=settings.anthropic_api_key)
           self._api_call_count = 0

       def run_poll_cycle(self) -> dict:
           """
           Execute one complete polling cycle.

           Returns:
               dict with keys: emails_fetched, emails_stored, emails_skipped, errors
           """
           stats = {
               "emails_fetched": 0,
               "emails_stored": 0,
               "emails_skipped": 0,
               "errors": 0,
           }

           logger.info("GmailPoller: Starting poll cycle")
           self._api_call_count = 0

           try:
               service = gmail_auth_service.get_service()
           except Exception as e:
               logger.error(f"GmailPoller: Auth failed, skipping cycle: {e}")
               stats["errors"] += 1
               return stats

           # Fetch message list from Gmail
           try:
               messages = self._list_messages(service)
           except Exception as e:
               logger.error(f"GmailPoller: Failed to list messages: {e}")
               stats["errors"] += 1
               return stats

           stats["emails_fetched"] = len(messages)
           logger.info(
               f"GmailPoller: Fetched {len(messages)} messages "
               f"(API calls: {self._api_call_count})"
           )

           # Process each message
           db = SessionLocal()
           try:
               for msg_stub in messages:
                   try:
                       stored = self._process_message(service, db, msg_stub["id"])
                       if stored:
                           stats["emails_stored"] += 1
                       else:
                           stats["emails_skipped"] += 1
                   except Exception as e:
                       logger.error(
                           f"GmailPoller: Error processing message {msg_stub['id']}: {e}"
                       )
                       stats["errors"] += 1
           finally:
               db.close()

           logger.info(
               f"GmailPoller: Cycle complete — "
               f"stored={stats['emails_stored']}, "
               f"skipped={stats['emails_skipped']}, "
               f"errors={stats['errors']}"
           )
           return stats

       def _list_messages(self, service) -> list[dict]:
           """
           Fetch list of unread message stubs from Gmail.

           Applies GMAIL_LABEL_FILTER if configured.
           Returns list of {id, threadId} dicts.
           """
           query_parts = ["is:unread"]

           if settings.gmail_label_filter:
               query_parts.append(f"label:{settings.gmail_label_filter}")

           query = " ".join(query_parts)

           response = self._call_gmail_api(
               service.users().messages().list,
               userId="me",
               q=query,
               maxResults=settings.gmail_max_results_per_poll,
           )

           return response.get("messages", [])

       def _process_message(self, service, db: Session, message_id: str) -> bool:
           """
           Fetch full message, match to project, deduplicate, and store.

           Returns True if a Source record was created, False if skipped.
           """
           # Fetch full message from Gmail
           msg = self._call_gmail_api(
               service.users().messages().get,
               userId="me",
               id=message_id,
               format="full",
           )

           # Extract headers
           headers = {h["name"]: h["value"] for h in msg.get("payload", {}).get("headers", [])}
           subject = headers.get("Subject", "(no subject)")
           from_raw = headers.get("From", "")
           to_raw = headers.get("To", "")
           cc_raw = headers.get("Cc", "")
           date_raw = headers.get("Date", "")
           thread_id = msg.get("threadId", "")
           label_ids = msg.get("labelIds", [])

           # Parse sender
           _, email_from = parseaddr(from_raw)

           # Parse recipients
           email_to = self._parse_address_list(to_raw)
           email_cc = self._parse_address_list(cc_raw)

           # Parse date
           occurred_at = self._parse_date(date_raw)

           # Decode email body
           raw_content = self._extract_body(msg.get("payload", {}))

           # Resolve Gmail label names for matching
           # Note: labelIds are IDs, not names — use subject-based matching as fallback
           label_names = self._resolve_label_names(service, label_ids)

           # Match to project
           project_id = email_matcher_service.match_project(
               db=db,
               gmail_labels=label_names,
               email_subject=subject,
               email_from=email_from,
           )

           if not project_id:
               logger.debug(f"GmailPoller: No project match for '{subject}', skipping")
               return False

           # Deduplicate: check for existing Source with same thread_id + message_id
           if self._is_duplicate(db, thread_id, message_id):
               logger.debug(
                   f"GmailPoller: Duplicate detected (thread={thread_id}, msg={message_id}), skipping"
               )
               return False

           # Generate AI summary
           ai_summary = self._generate_summary(subject, raw_content)

           # Create Source record
           source = Source(
               id=uuid4(),
               project_id=project_id,
               source_type="email",
               title=subject,
               occurred_at=occurred_at,
               ingestion_status="pending",
               raw_content=raw_content,
               ai_summary=ai_summary,
               email_from=email_from,
               email_to=email_to,
               email_cc=email_cc,
               email_thread_id=thread_id,
               webhook_id=message_id,  # Reused as deduplication key
           )

           db.add(source)
           db.commit()

           logger.info(
               f"GmailPoller: Stored Source for '{subject}' "
               f"(project={project_id}, thread={thread_id})"
           )
           return True

       def _is_duplicate(self, db: Session, thread_id: str, message_id: str) -> bool:
           """
           Check if a Source record already exists for this message.

           Uses email_thread_id + webhook_id (message ID) as composite key.
           """
           existing = db.query(Source).filter(
               Source.email_thread_id == thread_id,
               Source.webhook_id == message_id,
               Source.source_type == "email",
           ).first()
           return existing is not None

       def _generate_summary(self, subject: str, body: str) -> Optional[str]:
           """
           Generate a one-line AI summary of the email using Claude.

           Returns None if generation fails (non-blocking).
           """
           if not body:
               return None

           try:
               # Truncate body to avoid excessive token usage
               truncated_body = body[:3000] if len(body) > 3000 else body

               response = self.anthropic.messages.create(
                   model="claude-3-5-sonnet-20241022",
                   max_tokens=100,
                   temperature=0.0,
                   messages=[
                       {
                           "role": "user",
                           "content": (
                               f"Summarize this email in one sentence for a project manager. "
                               f"Subject: {subject}\n\n{truncated_body}"
                           ),
                       }
                   ],
               )

               summary = response.content[0].text.strip()

               # Enforce 150-character cap
               if len(summary) > 150:
                   summary = summary[:147] + "..."

               return summary

           except Exception as e:
               logger.warning(
                   f"GmailPoller: AI summary generation failed for '{subject}': {e}"
               )
               return None

       def _extract_body(self, payload: dict) -> str:
           """
           Extract plain text body from Gmail message payload.

           Handles both single-part and multipart messages.
           Prefers text/plain; falls back to stripping HTML from text/html.
           """
           mime_type = payload.get("mimeType", "")

           # Single-part message
           if mime_type in ("text/plain", "text/html"):
               data = payload.get("body", {}).get("data", "")
               if data:
                   decoded = base64.urlsafe_b64decode(data + "==").decode("utf-8", errors="replace")
                   return decoded if mime_type == "text/plain" else strip_html(decoded)

           # Multipart message — recurse through parts
           if mime_type.startswith("multipart/"):
               parts = payload.get("parts", [])

               # Prefer text/plain part
               for part in parts:
                   if part.get("mimeType") == "text/plain":
                       data = part.get("body", {}).get("data", "")
                       if data:
                           return base64.urlsafe_b64decode(data + "==").decode(
                               "utf-8", errors="replace"
                           )

               # Fall back to text/html
               for part in parts:
                   if part.get("mimeType") == "text/html":
                       data = part.get("body", {}).get("data", "")
                       if data:
                           html = base64.urlsafe_b64decode(data + "==").decode(
                               "utf-8", errors="replace"
                           )
                           return strip_html(html)

               # Recurse into nested multipart
               for part in parts:
                   if part.get("mimeType", "").startswith("multipart/"):
                       result = self._extract_body(part)
                       if result:
                           return result

           return ""

       def _parse_address_list(self, raw: str) -> list[str]:
           """Parse comma-separated email addresses into a list."""
           if not raw:
               return []
           addresses = []
           for addr in raw.split(","):
               _, email = parseaddr(addr.strip())
               if email:
                   addresses.append(email)
           return addresses

       def _parse_date(self, date_raw: str) -> datetime:
           """Parse RFC 2822 date string to UTC datetime."""
           try:
               dt = parsedate_to_datetime(date_raw)
               return dt.astimezone(timezone.utc).replace(tzinfo=None)
           except Exception:
               logger.warning(f"GmailPoller: Could not parse date '{date_raw}', using now()")
               return datetime.utcnow()

       def _resolve_label_names(self, service, label_ids: list[str]) -> list[str]:
           """
           Resolve Gmail label IDs to human-readable label names.

           System labels (INBOX, UNREAD, etc.) are excluded.
           """
           system_labels = {
               "INBOX", "SENT", "UNREAD", "STARRED", "IMPORTANT",
               "SPAM", "TRASH", "CATEGORY_PERSONAL", "CATEGORY_SOCIAL",
               "CATEGORY_PROMOTIONS", "CATEGORY_UPDATES", "CATEGORY_FORUMS",
           }
           names = []
           for label_id in label_ids:
               if label_id in system_labels:
                   continue
               try:
                   label_info = self._call_gmail_api(
                       service.users().labels().get,
                       userId="me",
                       id=label_id,
                   )
                   names.append(label_info.get("name", ""))
               except Exception as e:
                   logger.debug(f"GmailPoller: Could not resolve label {label_id}: {e}")
           return names

       def _call_gmail_api(self, method, **kwargs):
           """
           Execute a Gmail API method with exponential backoff retry.

           Args:
               method: Bound method from googleapiclient (e.g., service.users().messages().list)
               **kwargs: Arguments forwarded to the method

           Returns:
               API response dict

           Raises:
               HttpError: If all retries exhausted
           """
           self._api_call_count += 1
           last_error = None

           for attempt in range(MAX_RETRIES):
               try:
                   return method(**kwargs).execute()
               except HttpError as e:
                   if e.status_code in (429, 500, 503):
                       wait_seconds = RETRY_BASE_SECONDS * (2 ** attempt)
                       logger.warning(
                           f"GmailPoller: API error {e.status_code} on attempt {attempt + 1}/"
                           f"{MAX_RETRIES}. Retrying in {wait_seconds}s..."
                       )
                       time.sleep(wait_seconds)
                       last_error = e
                   else:
                       # Non-retryable error (e.g., 403 forbidden, 404 not found)
                       logger.error(f"GmailPoller: Non-retryable API error {e.status_code}: {e}")
                       raise

           logger.error(
               f"GmailPoller: Max retries ({MAX_RETRIES}) exhausted. Last error: {last_error}"
           )
           raise last_error


   # Singleton instance
   gmail_poller_service = GmailPollerService()
   ```

### Task 5: Create APScheduler Background Scheduler (0.5 days)

1. **Create `decision-log-backend/app/scheduler.py`**

   ```python
   """Background job scheduler using APScheduler."""

   import logging
   from datetime import datetime

   from apscheduler.schedulers.background import BackgroundScheduler
   from apscheduler.triggers.interval import IntervalTrigger

   from app.config import settings

   logger = logging.getLogger(__name__)

   # Minimum poll interval to prevent quota exhaustion
   MIN_POLL_INTERVAL_MINUTES = 5


   def _run_gmail_poll():
       """
       Wrapper function executed by the scheduler.

       Imports inside the function to avoid circular imports at startup.
       """
       from app.services.gmail_poller import gmail_poller_service

       logger.info("Scheduler: Running Gmail poll cycle")
       try:
           stats = gmail_poller_service.run_poll_cycle()
           logger.info(f"Scheduler: Gmail poll complete — {stats}")
       except Exception as e:
           logger.error(f"Scheduler: Gmail poll failed with unhandled exception: {e}")


   class AppScheduler:
       """Manages background job scheduling for the application."""

       def __init__(self):
           self._scheduler = BackgroundScheduler()
           self._gmail_job = None

       def start(self):
           """
           Start the background scheduler and register jobs.

           Called on FastAPI startup event.
           """
           if not settings.is_gmail_configured():
               logger.info(
                   "Scheduler: Gmail credentials not configured — "
                   "Gmail poller disabled. Set GMAIL_CLIENT_ID, "
                   "GMAIL_CLIENT_SECRET, GMAIL_REFRESH_TOKEN to enable."
               )
               return

           # Enforce minimum interval
           interval_minutes = max(
               settings.gmail_poll_interval_minutes,
               MIN_POLL_INTERVAL_MINUTES,
           )

           if interval_minutes != settings.gmail_poll_interval_minutes:
               logger.warning(
                   f"Scheduler: GMAIL_POLL_INTERVAL_MINUTES={settings.gmail_poll_interval_minutes} "
                   f"is below minimum ({MIN_POLL_INTERVAL_MINUTES}). "
                   f"Using {MIN_POLL_INTERVAL_MINUTES} minutes."
               )

           logger.info(
               f"Scheduler: Registering Gmail poller — "
               f"interval={interval_minutes}m, "
               f"label_filter='{settings.gmail_label_filter}', "
               f"max_results={settings.gmail_max_results_per_poll}"
           )

           self._gmail_job = self._scheduler.add_job(
               _run_gmail_poll,
               trigger=IntervalTrigger(minutes=interval_minutes),
               id="gmail_poller",
               name="Gmail Email Poller",
               max_instances=1,  # Prevent overlapping runs
               coalesce=True,    # Skip missed runs instead of catching up
               misfire_grace_time=60,  # Allow 60s late start before considering misfired
           )

           self._scheduler.start()
           logger.info(
               f"Scheduler: Started. Gmail poller next run: "
               f"{self._gmail_job.next_run_time}"
           )

       def shutdown(self):
           """
           Gracefully shut down the scheduler.

           Called on FastAPI shutdown event.
           """
           if self._scheduler.running:
               self._scheduler.shutdown(wait=False)
               logger.info("Scheduler: Shut down")

       def get_status(self) -> dict:
           """Return scheduler status for admin monitoring endpoint."""
           if not self._scheduler.running:
               return {"running": False, "jobs": []}

           jobs = []
           for job in self._scheduler.get_jobs():
               jobs.append({
                   "id": job.id,
                   "name": job.name,
                   "next_run_time": job.next_run_time.isoformat() if job.next_run_time else None,
               })

           return {"running": True, "jobs": jobs}


   # Singleton instance
   app_scheduler = AppScheduler()
   ```

2. **Register scheduler with FastAPI in `decision-log-backend/app/main.py`**

   ```python
   # Add to FastAPI lifespan or startup/shutdown events:

   from app.scheduler import app_scheduler

   @app.on_event("startup")
   async def startup_event():
       app_scheduler.start()

   @app.on_event("shutdown")
   async def shutdown_event():
       app_scheduler.shutdown()
   ```

### Task 6: Add Scheduler Status Admin Endpoint (0.25 days)

1. **Add to `decision-log-backend/app/api/routes/admin.py`** (create if not exists):

   ```python
   """Admin-only endpoints for system monitoring."""

   from fastapi import APIRouter, Depends

   from app.api.middleware.auth import require_admin
   from app.scheduler import app_scheduler

   router = APIRouter(prefix="/api/admin", tags=["admin"])


   @router.get("/scheduler/status")
   async def get_scheduler_status(current_user=Depends(require_admin)):
       """Return background scheduler status. Admin only."""
       return app_scheduler.get_status()
   ```

2. **Register router in `app/main.py`**:

   ```python
   from app.api.routes.admin import router as admin_router
   app.include_router(admin_router)
   ```

### Task 7: Install Dependencies (0.25 days)

1. **Update `decision-log-backend/requirements.txt`**:

   ```
   # Add these dependencies (existing entries preserved):
   google-api-python-client==2.118.0
   google-auth==2.28.1
   google-auth-oauthlib==1.2.0
   google-auth-httplib2==0.2.0
   APScheduler==3.10.4
   ```

2. **Install locally**:

   ```bash
   cd decision-log-backend
   pip install google-api-python-client google-auth google-auth-oauthlib google-auth-httplib2 APScheduler
   ```

### Task 8: Write Unit and Integration Tests (0.75 days)

See Testing Strategy section below for full test file content.

1. **Create `decision-log-backend/tests/unit/test_gmail_poller.py`**
2. **Create `decision-log-backend/tests/unit/test_email_matcher.py`**
3. **Create `decision-log-backend/tests/unit/test_gmail_auth.py`**

---

## Dev Notes

### Gmail API OAuth2 Setup Guide

Two authentication flows are supported:

**Option A — Service Account (recommended for production)**

Suitable for accessing a shared Google Workspace account (e.g., `projects@soubim.com`):

1. Create a service account in Google Cloud Console
2. Enable the Gmail API in the project
3. Enable domain-wide delegation for the service account
4. Grant the service account the `https://www.googleapis.com/auth/gmail.readonly` scope
5. Download the service account JSON key file
6. Base64-encode it: `base64 -w 0 service-account.json`
7. Set `GMAIL_SERVICE_ACCOUNT_JSON=<encoded-value>` in `.env`

**Option B — OAuth2 User Consent (for personal Gmail accounts)**

Suitable for development or single-user setups:

1. Create OAuth2 credentials (Web or Desktop app) in Google Cloud Console
2. Run the consent flow once to obtain a refresh token
3. Use a helper script to get the initial refresh token:

   ```python
   from google_auth_oauthlib.flow import InstalledAppFlow
   flow = InstalledAppFlow.from_client_secrets_file("credentials.json", GMAIL_SCOPES)
   creds = flow.run_local_server(port=0)
   print("Refresh token:", creds.refresh_token)
   ```

4. Set `GMAIL_CLIENT_ID`, `GMAIL_CLIENT_SECRET`, `GMAIL_REFRESH_TOKEN` in `.env`

### Gmail Label Strategy for Project Matching

Labels are the most reliable matching mechanism. Recommended convention:

- Create one Gmail label per project: `soubim/skyline-tower`, `soubim/harbor-district`
- Train team members to apply the label when forwarding project emails to the shared inbox
- The `EmailMatcherService` strips the `soubim/` prefix before matching to project title

Fallback: if no label matches, the email subject is scanned for the project title. This catches forwarded emails that were not manually labeled.

### Deduplication Strategy

The `webhook_id` column (originally for Tactiq webhook IDs) is repurposed as a general-purpose deduplication key. For Gmail emails, it stores the Gmail message ID (e.g., `189abc123def`).

The composite check `(email_thread_id, webhook_id, source_type='email')` ensures:
- The same message is never stored twice (even if the poller runs multiple times before the email is read/labeled)
- Multiple distinct messages within the same thread ARE stored as separate Source records (each has a unique message ID)

### APScheduler Configuration Choices

`max_instances=1` prevents overlapping poll cycles. If a cycle takes longer than the interval (unlikely, but possible during Gmail outages or large backlogs), the next scheduled trigger is skipped rather than starting a second concurrent job.

`coalesce=True` means if the server was down and multiple triggers were missed, only one catch-up run fires upon restart rather than one run per missed trigger.

### Exponential Backoff Reference

| Attempt | Wait Before Retry |
|---------|------------------|
| 1 | 1 second |
| 2 | 2 seconds |
| 3 | 4 seconds |
| 4 | 8 seconds |
| 5 | 16 seconds |
| Exhausted | Raise HttpError, skip cycle |

Gmail's standard quota is 250 quota units per user per second. A `messages.list` call costs 5 units; `messages.get` costs 5 units. With `GMAIL_MAX_RESULTS_PER_POLL=50`, one cycle costs approximately 5 + (50 × 5) = 255 units over the entire cycle duration, well within limits.

### HTML Email Body Handling

Gmail delivers email bodies base64url-encoded. Many real-world emails are HTML-only (no `text/plain` part). The `HTMLStripper` class uses Python's built-in `html.parser` — no external dependency required.

Attachments are intentionally ignored in this story. The `raw_content` field stores only the email body text. Attachment handling (file download, drive storage) is deferred to Phase 2 (Story 10.2 or later).

### Source Model Email Fields Reference

The `Source` model (from Story 5.1) includes these email-specific fields:

```python
email_from: str          # sender address (e.g., "carlos@example.com")
email_to: list[str]      # JSONB — primary recipient list
email_cc: list[str]      # JSONB — CC recipient list
email_thread_id: str     # Gmail thread ID (groups related messages)
webhook_id: str          # Gmail message ID (unique per message, used for dedup)
```

The `webhook_id` column has a partial unique index: `idx_sources_webhook ON sources(webhook_id) WHERE webhook_id IS NOT NULL`. This enforces deduplication at the database level as a safety net beyond the application-level check.

### Gmail Poller Disabled Gracefully

If `GMAIL_CLIENT_ID`/`GMAIL_SERVICE_ACCOUNT_JSON` are not set, the scheduler starts but does not register the Gmail job. The server starts normally — the poller is opt-in. This is important for local development where developers may not have Gmail credentials.

---

## File List

**New Files:**
- `decision-log-backend/app/services/gmail_poller.py` — Gmail polling service (core ingestion logic)
- `decision-log-backend/app/services/email_matcher.py` — Email-to-project matching service
- `decision-log-backend/app/services/gmail_auth.py` — Gmail OAuth2 authentication service
- `decision-log-backend/app/scheduler.py` — APScheduler background job manager
- `decision-log-backend/app/api/routes/admin.py` — Admin monitoring endpoints (scheduler status)
- `decision-log-backend/tests/unit/test_gmail_poller.py` — Gmail poller unit tests
- `decision-log-backend/tests/unit/test_email_matcher.py` — Email matcher unit tests
- `decision-log-backend/tests/unit/test_gmail_auth.py` — Auth service unit tests

**Modified Files:**
- `decision-log-backend/app/config.py` — Add `gmail_poll_interval_minutes`, `gmail_label_filter`, `gmail_max_results_per_poll`, `gmail_client_id`, `gmail_client_secret`, `gmail_refresh_token`, `gmail_service_account_json`, `is_gmail_configured()`
- `decision-log-backend/app/main.py` — Register scheduler startup/shutdown events and admin router
- `decision-log-backend/requirements.txt` — Add `google-api-python-client`, `google-auth`, `google-auth-oauthlib`, `google-auth-httplib2`, `APScheduler`

---

## Testing Strategy

### Unit Tests

**`decision-log-backend/tests/unit/test_gmail_poller.py`**

```python
"""Unit tests for Gmail poller service."""

import pytest
from unittest.mock import MagicMock, patch, call
from datetime import datetime, timezone

from app.services.gmail_poller import GmailPollerService, strip_html


# --- Utility function tests ---

class TestStripHtml:
    """Test HTML stripping utility."""

    def test_strips_basic_html_tags(self):
        html = "<p>Hello <b>World</b></p>"
        assert "Hello" in strip_html(html)
        assert "World" in strip_html(html)
        assert "<p>" not in strip_html(html)

    def test_handles_plain_text(self):
        text = "No HTML here"
        assert strip_html(text) == text

    def test_handles_empty_string(self):
        assert strip_html("") == ""

    def test_strips_anchor_tags(self):
        html = '<a href="https://example.com">Click here</a>'
        result = strip_html(html)
        assert "Click here" in result
        assert "<a" not in result


# --- GmailPollerService tests ---

@pytest.fixture
def poller():
    """Create a GmailPollerService instance with mocked Anthropic client."""
    with patch("app.services.gmail_poller.Anthropic"):
        service = GmailPollerService()
    return service


@pytest.fixture
def mock_db():
    """Mock SQLAlchemy session."""
    return MagicMock()


class TestGmailPollerDeduplication:
    """Test deduplication logic."""

    def test_detects_duplicate_by_thread_and_message_id(self, poller, mock_db):
        """Deduplication returns True when matching Source exists."""
        from app.database.models import Source
        existing = MagicMock(spec=Source)
        mock_db.query.return_value.filter.return_value.first.return_value = existing

        result = poller._is_duplicate(mock_db, "thread123", "msg456")

        assert result is True

    def test_no_duplicate_when_source_absent(self, poller, mock_db):
        """Deduplication returns False when no matching Source exists."""
        mock_db.query.return_value.filter.return_value.first.return_value = None

        result = poller._is_duplicate(mock_db, "thread123", "msg456")

        assert result is False


class TestGmailPollerBodyExtraction:
    """Test email body extraction from Gmail payload."""

    def test_extracts_plaintext_body(self, poller):
        """Extracts decoded plain text from text/plain part."""
        import base64
        body_text = "Hello, this is the email body."
        encoded = base64.urlsafe_b64encode(body_text.encode()).decode()

        payload = {
            "mimeType": "text/plain",
            "body": {"data": encoded},
        }

        result = poller._extract_body(payload)
        assert result == body_text

    def test_extracts_html_body_stripped(self, poller):
        """Extracts and strips HTML from text/html part."""
        import base64
        body_html = "<p>Project update: <b>approved</b></p>"
        encoded = base64.urlsafe_b64encode(body_html.encode()).decode()

        payload = {
            "mimeType": "text/html",
            "body": {"data": encoded},
        }

        result = poller._extract_body(payload)
        assert "Project update" in result
        assert "approved" in result
        assert "<p>" not in result

    def test_prefers_plaintext_over_html_in_multipart(self, poller):
        """Prefers text/plain when both parts exist in multipart."""
        import base64
        plain = base64.urlsafe_b64encode(b"Plain text body").decode()
        html = base64.urlsafe_b64encode(b"<p>HTML body</p>").decode()

        payload = {
            "mimeType": "multipart/alternative",
            "parts": [
                {"mimeType": "text/html", "body": {"data": html}},
                {"mimeType": "text/plain", "body": {"data": plain}},
            ],
        }

        result = poller._extract_body(payload)
        assert "Plain text body" in result

    def test_returns_empty_string_for_unsupported_type(self, poller):
        """Returns empty string when no text body is found."""
        payload = {
            "mimeType": "application/pdf",
            "body": {},
        }
        result = poller._extract_body(payload)
        assert result == ""


class TestGmailPollerAddressParsing:
    """Test email address parsing."""

    def test_parses_single_address(self, poller):
        result = poller._parse_address_list("carlos@example.com")
        assert result == ["carlos@example.com"]

    def test_parses_display_name_with_address(self, poller):
        result = poller._parse_address_list("Carlos Perez <carlos@example.com>")
        assert result == ["carlos@example.com"]

    def test_parses_multiple_addresses(self, poller):
        raw = "carlos@example.com, elena@example.com, morgan@example.com"
        result = poller._parse_address_list(raw)
        assert len(result) == 3
        assert "carlos@example.com" in result

    def test_returns_empty_for_empty_input(self, poller):
        assert poller._parse_address_list("") == []


class TestGmailPollerDateParsing:
    """Test RFC 2822 date parsing."""

    def test_parses_valid_rfc2822_date(self, poller):
        date_str = "Wed, 19 Feb 2026 10:30:00 +0000"
        result = poller._parse_date(date_str)
        assert isinstance(result, datetime)
        assert result.year == 2026
        assert result.month == 2
        assert result.day == 19

    def test_falls_back_to_now_for_invalid_date(self, poller):
        """Invalid date string returns current time without raising."""
        before = datetime.utcnow()
        result = poller._parse_date("not-a-date")
        after = datetime.utcnow()
        assert before <= result <= after


class TestGmailPollerExponentialBackoff:
    """Test API retry logic."""

    def test_retries_on_429_quota_exceeded(self, poller):
        """Retries on quota exceeded and eventually raises after max retries."""
        from googleapiclient.errors import HttpError
        import httplib2

        mock_response = httplib2.Response({"status": "429"})
        quota_error = HttpError(resp=mock_response, content=b"Quota exceeded")

        mock_method = MagicMock(return_value=MagicMock())
        mock_method.return_value.execute.side_effect = [quota_error] * MAX_RETRIES

        with patch("app.services.gmail_poller.MAX_RETRIES", 2):
            with patch("app.services.gmail_poller.time.sleep") as mock_sleep:
                with pytest.raises(HttpError):
                    poller._call_gmail_api(mock_method, userId="me")

        # Sleep called between retries
        assert mock_sleep.called

    def test_succeeds_after_transient_failure(self, poller):
        """Returns result after one transient failure."""
        from googleapiclient.errors import HttpError
        import httplib2

        mock_response = httplib2.Response({"status": "503"})
        transient_error = HttpError(resp=mock_response, content=b"Service unavailable")

        mock_execute = MagicMock(side_effect=[transient_error, {"messages": []}])
        mock_method = MagicMock(return_value=MagicMock(execute=mock_execute))

        with patch("app.services.gmail_poller.time.sleep"):
            result = poller._call_gmail_api(mock_method, userId="me")

        assert result == {"messages": []}


class TestGmailPollerAISummary:
    """Test AI summary generation."""

    def test_generates_summary_successfully(self, poller):
        """Returns Claude-generated summary."""
        mock_response = MagicMock()
        mock_response.content = [MagicMock(text="Project kickoff confirmed for March 2026.")]
        poller.anthropic.messages.create.return_value = mock_response

        result = poller._generate_summary("Project Kickoff", "The meeting is confirmed for March.")

        assert result == "Project kickoff confirmed for March 2026."

    def test_truncates_summary_over_150_chars(self, poller):
        """Truncates summary exceeding 150 characters."""
        long_summary = "A" * 200
        mock_response = MagicMock()
        mock_response.content = [MagicMock(text=long_summary)]
        poller.anthropic.messages.create.return_value = mock_response

        result = poller._generate_summary("Subject", "Body")

        assert len(result) <= 150
        assert result.endswith("...")

    def test_returns_none_on_api_failure(self, poller):
        """Returns None (not raises) when Claude API fails."""
        poller.anthropic.messages.create.side_effect = Exception("API error")

        result = poller._generate_summary("Subject", "Body")

        assert result is None

    def test_returns_none_for_empty_body(self, poller):
        """Returns None without calling API when body is empty."""
        result = poller._generate_summary("Subject", "")

        poller.anthropic.messages.create.assert_not_called()
        assert result is None
```

**`decision-log-backend/tests/unit/test_email_matcher.py`**

```python
"""Unit tests for email matcher service."""

import pytest
from unittest.mock import MagicMock

from app.services.email_matcher import EmailMatcherService


@pytest.fixture
def matcher():
    return EmailMatcherService()


@pytest.fixture
def mock_projects():
    """Two mock Project objects."""
    p1 = MagicMock()
    p1.id = "project-uuid-1"
    p1.title = "Skyline Tower"
    p1.archived_at = None

    p2 = MagicMock()
    p2.id = "project-uuid-2"
    p2.title = "Harbor District"
    p2.archived_at = None

    return [p1, p2]


@pytest.fixture
def mock_db(mock_projects):
    db = MagicMock()
    db.query.return_value.filter.return_value.all.return_value = mock_projects
    return db


class TestEmailMatcher:

    def test_matches_via_project_label(self, matcher, mock_db):
        """Matches project by Gmail label 'project/skyline-tower'."""
        result = matcher.match_project(
            db=mock_db,
            gmail_labels=["project/skyline-tower"],
            email_subject="Update",
            email_from="sender@example.com",
        )
        assert result == "project-uuid-1"

    def test_matches_via_soubim_prefix_label(self, matcher, mock_db):
        """Matches project by Gmail label 'soubim/harbor-district'."""
        result = matcher.match_project(
            db=mock_db,
            gmail_labels=["soubim/harbor-district"],
            email_subject="Update",
            email_from="sender@example.com",
        )
        assert result == "project-uuid-2"

    def test_matches_via_subject_fallback(self, matcher, mock_db):
        """Falls back to subject matching when no label matches."""
        result = matcher.match_project(
            db=mock_db,
            gmail_labels=["INBOX"],
            email_subject="Skyline Tower: structural update",
            email_from="sender@example.com",
        )
        assert result == "project-uuid-1"

    def test_returns_none_when_no_match(self, matcher, mock_db):
        """Returns None when no project matches."""
        result = matcher.match_project(
            db=mock_db,
            gmail_labels=["INBOX"],
            email_subject="Completely unrelated email",
            email_from="spam@example.com",
        )
        assert result is None

    def test_returns_none_when_no_projects(self, matcher):
        """Returns None when database has no active projects."""
        db = MagicMock()
        db.query.return_value.filter.return_value.all.return_value = []

        result = matcher.match_project(
            db=db,
            gmail_labels=["project/anything"],
            email_subject="Any subject",
            email_from="sender@example.com",
        )
        assert result is None

    def test_label_matching_case_insensitive(self, matcher, mock_db):
        """Label matching is case-insensitive."""
        result = matcher.match_project(
            db=mock_db,
            gmail_labels=["Project/SKYLINE-TOWER"],
            email_subject="Update",
            email_from="sender@example.com",
        )
        assert result == "project-uuid-1"
```

### Integration Tests

**`decision-log-backend/tests/integration/test_gmail_poller_integration.py`**

```python
"""
Integration tests for Gmail poller end-to-end flow.

These tests mock the Gmail API but use a real database session.
Mark with @pytest.mark.integration to run separately from unit tests.
"""

import pytest
from unittest.mock import MagicMock, patch
from datetime import datetime

from app.services.gmail_poller import GmailPollerService
from app.database.models import Source


@pytest.mark.integration
class TestGmailPollerIntegration:

    def test_full_poll_cycle_creates_source_record(self, db_session, sample_project):
        """End-to-end: poll cycle creates pending Source record for matched email."""
        # Mock Gmail API response
        mock_message = {
            "id": "msg001",
            "threadId": "thread001",
            "labelIds": [],
            "payload": {
                "mimeType": "text/plain",
                "headers": [
                    {"name": "Subject", "value": "Skyline Tower: Permit approved"},
                    {"name": "From", "value": "city@permits.gov"},
                    {"name": "To", "value": "projects@soubim.com"},
                    {"name": "Date", "value": "Wed, 19 Feb 2026 10:00:00 +0000"},
                ],
                "body": {"data": _b64("The environmental permit has been approved.")},
            },
        }

        with patch("app.services.gmail_poller.gmail_auth_service") as mock_auth, \
             patch("app.services.gmail_poller.email_matcher_service") as mock_matcher, \
             patch("app.services.gmail_poller.SessionLocal", return_value=db_session):

            mock_service = MagicMock()
            mock_auth.get_service.return_value = mock_service
            mock_service.users.return_value.messages.return_value.list.return_value \
                .execute.return_value = {"messages": [{"id": "msg001", "threadId": "thread001"}]}
            mock_service.users.return_value.messages.return_value.get.return_value \
                .execute.return_value = mock_message
            mock_service.users.return_value.labels.return_value.get.return_value \
                .execute.return_value = {"name": "INBOX"}

            mock_matcher.match_project.return_value = str(sample_project.id)

            with patch("app.services.gmail_poller.Anthropic"):
                poller = GmailPollerService()
                poller.anthropic.messages.create.return_value.content = [
                    MagicMock(text="City approved environmental permit for Skyline Tower.")
                ]
                stats = poller.run_poll_cycle()

        assert stats["emails_stored"] == 1
        assert stats["emails_skipped"] == 0

        source = db_session.query(Source).filter(
            Source.webhook_id == "msg001"
        ).first()

        assert source is not None
        assert source.source_type == "email"
        assert source.ingestion_status == "pending"
        assert source.email_thread_id == "thread001"
        assert source.title == "Skyline Tower: Permit approved"
        assert "approved" in source.raw_content

    def test_duplicate_email_not_stored_twice(self, db_session, sample_project, sample_email_source):
        """Deduplication: second poll with same message ID skips creation."""
        with patch("app.services.gmail_poller.gmail_auth_service") as mock_auth, \
             patch("app.services.gmail_poller.email_matcher_service") as mock_matcher, \
             patch("app.services.gmail_poller.SessionLocal", return_value=db_session):

            # Configure mocks to return the same message that already exists
            mock_service = MagicMock()
            mock_auth.get_service.return_value = mock_service
            mock_service.users.return_value.messages.return_value.list.return_value \
                .execute.return_value = {
                    "messages": [{"id": sample_email_source.webhook_id, "threadId": sample_email_source.email_thread_id}]
                }

            with patch("app.services.gmail_poller.Anthropic"):
                poller = GmailPollerService()
                stats = poller.run_poll_cycle()

        assert stats["emails_skipped"] == 1
        assert stats["emails_stored"] == 0

        # Only the original source record exists
        count = db_session.query(Source).filter(
            Source.webhook_id == sample_email_source.webhook_id
        ).count()
        assert count == 1


def _b64(text: str) -> str:
    """Base64url-encode a string for Gmail mock payloads."""
    import base64
    return base64.urlsafe_b64encode(text.encode()).decode()
```

### Coverage Target

- `gmail_poller.py`: 85%+
- `email_matcher.py`: 90%+
- `gmail_auth.py`: 75%+ (lower due to external auth flows)
- `scheduler.py`: 80%+

**Run unit tests:**
```bash
cd decision-log-backend && python3 -m pytest tests/unit/test_gmail_poller.py tests/unit/test_email_matcher.py tests/unit/test_gmail_auth.py -v
```

**Run integration tests:**
```bash
cd decision-log-backend && python3 -m pytest tests/integration/test_gmail_poller_integration.py -v -m integration
```

**Run with coverage:**
```bash
cd decision-log-backend && python3 -m pytest tests/unit/ -v --cov=app/services/gmail_poller --cov=app/services/email_matcher --cov=app/services/gmail_auth --cov=app/scheduler --cov-report=term-missing
```

### Manual Verification Steps

1. Set Gmail credentials in `.env.development`
2. Start the backend: `npm run backend:dev`
3. Observe scheduler logs on startup: `"Scheduler: Registering Gmail poller — interval=30m"`
4. Trigger one immediate poll via admin endpoint or restart with `GMAIL_POLL_INTERVAL_MINUTES=1`
5. Check `sources` table: `SELECT * FROM sources WHERE source_type='email' ORDER BY created_at DESC LIMIT 5;`
6. Verify emails appear in Ingestion Approval: `GET /api/ingestion?source_type=email`
7. Confirm polled emails display in Ingestion Approval page (Story 7.2 frontend)

---

## Change Log

| Date | Change |
|------|--------|
| 2026-02-19 | Created story with full Gmail poller, email matcher, auth service, APScheduler setup, and unit/integration test suite |

---

**Related Stories:** 7.1 (Source entity & ingestion queue), 7.2 (Ingestion Approval page displays polled emails)
**Blocked By:** 5.1 (sources table must exist), 7.1 (ingestion queue and Source model must exist)
**Blocks:** 10.1 (Email item extraction pipeline consumes Source records created here)
