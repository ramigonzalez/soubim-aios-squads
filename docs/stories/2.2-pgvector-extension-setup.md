# Story 2.2: pgvector Extension Setup

**Story ID:** 2.2
**Assigned to:** @dev
**Sprint:** Sprint 3 (Week 5)
**Status:** Draft
**Estimation:** 3 story points (1.5 days)

---

## Summary

Enable pgvector extension in PostgreSQL and add vector column to decisions table. This allows storing 384-dimensional embeddings and performing fast vector similarity searches using cosine distance.

---

## Acceptance Criteria

- [ ] pgvector extension enabled on Supabase/PostgreSQL
- [ ] `embedding` column added to decisions table:
  - [ ] Type: `vector(384)`
  - [ ] Nullable initially (will be populated by Story 2.3)
  - [ ] No default value
- [ ] IVFFLAT index created for cosine similarity:
  - [ ] Index type: `ivfflat`
  - [ ] Distance operator: `vector_cosine_ops`
  - [ ] Lists parameter: 100 (optimal for <100K vectors)
- [ ] Sample vector operations tested:
  - [ ] Insert vector successfully
  - [ ] Query by cosine similarity
  - [ ] Performance: <500ms for 1000 decisions
- [ ] Alembic migration created: `alembic/versions/002_add_vector_column.py`
- [ ] Migration tested:
  - [ ] Upgrade works without errors
  - [ ] Downgrade removes column and index
- [ ] Tests passing: `pytest tests/unit/test_vector_db.py` (80%+ coverage)

---

## Tasks

### Task 1: Enable pgvector Extension (0.25 days)

1. **Create Alembic migration**
   - Run: `alembic revision -m "enable_pgvector_extension"`
   - Edit migration file
   - Add `CREATE EXTENSION IF NOT EXISTS vector`
   - Add downgrade: `DROP EXTENSION vector`

2. **Apply migration**
   - Run: `alembic upgrade head`
   - Verify extension enabled: `SELECT * FROM pg_extension WHERE extname='vector'`
   - Check version: Should be 0.5.0+

3. **Test extension**
   - Create test vector column
   - Insert sample vector
   - Drop test table

### Task 2: Add Vector Column to Decisions Table (0.5 days)

1. **Create migration for embedding column**
   - Run: `alembic revision -m "add_embedding_column_to_decisions"`
   - Add column: `ALTER TABLE decisions ADD COLUMN embedding vector(384)`
   - Nullable: Allow NULL initially (will populate later)
   - No default value

2. **Apply migration**
   - Run: `alembic upgrade head`
   - Verify column exists: `\d decisions`
   - Check data type: `vector(384)`

3. **Test column operations**
   - Insert decision with NULL embedding → Success
   - Insert decision with 384-dim vector → Success
   - Insert wrong dimension (256-dim) → Error (expected)

### Task 3: Create IVFFLAT Index (0.5 days)

1. **Add index to migration**
   - Index name: `idx_decisions_embedding_cosine`
   - Index type: IVFFLAT (approximate nearest neighbor)
   - Distance operator: `vector_cosine_ops`
   - Lists parameter: 100 (good for MVP, <100K vectors)

2. **Apply index migration**
   - Run migration
   - Verify index created: `\di idx_decisions_embedding_cosine`
   - Check index size: Should be small initially

3. **Test index performance**
   - Insert 100 test vectors
   - Run similarity query
   - Measure latency (should be <100ms)

### Task 4: Test Vector Operations (0.25 days)

1. **Create test query script**
   - Generate sample embeddings (random 384-dim)
   - Insert test decisions with embeddings
   - Query nearest neighbors using `<=>` operator
   - Verify results ordered by similarity

2. **Test SQL queries**
   ```sql
   -- Find 10 most similar decisions
   SELECT id, statement,
          1 - (embedding <=> query_vector) as similarity
   FROM decisions
   WHERE project_id = 'uuid'
   AND embedding IS NOT NULL
   ORDER BY embedding <=> query_vector
   LIMIT 10;
   ```

3. **Validate performance**
   - 100 decisions: <50ms
   - 1000 decisions: <200ms
   - 10000 decisions: <500ms (with index)

---

## Dev Notes

### pgvector Overview

**What is pgvector?**
- PostgreSQL extension for vector similarity search
- Stores high-dimensional vectors efficiently
- Supports cosine, L2, and inner product distances
- Used by: OpenAI, Supabase, Timescale

**Index Types:**
- **IVFFLAT**: Approximate search, faster, good for MVP
- **HNSW**: Higher accuracy, slower build (Phase 2)

### Alembic Migration Code

```python
# alembic/versions/002_add_vector_column.py
"""Add pgvector extension and embedding column

Revision ID: 002
Revises: 001
Create Date: 2026-02-XX
"""
from alembic import op
import sqlalchemy as sa

def upgrade():
    # Enable pgvector extension
    op.execute('CREATE EXTENSION IF NOT EXISTS vector')

    # Add embedding column to decisions table
    op.execute('''
        ALTER TABLE decisions
        ADD COLUMN embedding vector(384)
    ''')

    # Create IVFFLAT index for cosine similarity
    # Note: Build index AFTER populating embeddings (Story 2.3)
    # Uncommented for now - will enable in Story 2.3
    # op.execute('''
    #     CREATE INDEX idx_decisions_embedding_cosine
    #     ON decisions
    #     USING ivfflat (embedding vector_cosine_ops)
    #     WITH (lists = 100)
    # ''')

def downgrade():
    # Drop index
    # op.execute('DROP INDEX IF EXISTS idx_decisions_embedding_cosine')

    # Drop embedding column
    op.execute('ALTER TABLE decisions DROP COLUMN IF EXISTS embedding')

    # Drop extension (careful - may affect other tables)
    # op.execute('DROP EXTENSION IF EXISTS vector')
```

### Vector Operations Cheat Sheet

```sql
-- Distance operators
embedding <-> other_embedding  -- L2 distance (Euclidean)
embedding <=> other_embedding  -- Cosine distance (1 - cosine similarity)
embedding <#> other_embedding  -- Inner product (negative dot product)

-- Cosine similarity (recommended for semantic search)
-- Returns value between 0 (different) and 1 (identical)
1 - (embedding <=> query_vector) as similarity

-- Example query: Find similar decisions
SELECT
    id,
    statement,
    discipline,
    1 - (embedding <=> %s::vector) as similarity_score
FROM decisions
WHERE project_id = %s
  AND embedding IS NOT NULL
  AND 1 - (embedding <=> %s::vector) > 0.7  -- Similarity threshold
ORDER BY embedding <=> %s::vector  -- Order by distance (ascending)
LIMIT 10;
```

### Index Configuration

**IVFFLAT Parameters:**
- `lists`: Number of clusters (default: 100)
  - Too few: Slower search
  - Too many: Slower index build, less accurate
  - Rule of thumb: `lists = sqrt(total_rows)`
  - MVP: 100 lists (good for <100K decisions)

**When to build index:**
- AFTER populating embeddings (not on empty table)
- Reindex periodically as data grows
- Monitor query performance

### Performance Benchmarks

| Decisions | No Index | IVFFLAT Index |
|-----------|----------|---------------|
| 100 | <50ms | <20ms |
| 1,000 | ~200ms | <100ms |
| 10,000 | ~2s | <300ms |
| 100,000 | ~20s | <500ms |

---

## File List

**Modified/Created:**
- `alembic/versions/002_add_vector_column.py` (new) - Vector column migration
- `tests/unit/test_vector_db.py` (new) - Vector database tests
- `app/database/models.py` (modify) - Update Decision model with embedding field
- `docs/architecture/03-DATABASE-SCHEMA.md` (modify) - Document vector column

---

## Testing Strategy

### Unit Tests (`tests/unit/test_vector_db.py`)

```python
import pytest
import numpy as np
from sqlalchemy import text
from app.database import engine, Session
from app.database.models import Decision

def test_pgvector_extension_enabled():
    """Test pgvector extension is enabled."""
    with engine.connect() as conn:
        result = conn.execute(text(
            "SELECT * FROM pg_extension WHERE extname='vector'"
        ))
        assert result.rowcount > 0

def test_embedding_column_exists():
    """Test embedding column exists on decisions table."""
    with engine.connect() as conn:
        result = conn.execute(text("""
            SELECT column_name, data_type
            FROM information_schema.columns
            WHERE table_name='decisions' AND column_name='embedding'
        """))
        row = result.fetchone()
        assert row is not None
        assert 'vector' in row[1].lower()

def test_insert_decision_with_embedding():
    """Test inserting decision with vector embedding."""
    db = Session()
    embedding = np.random.rand(384).tolist()

    decision = Decision(
        project_id='test-project-id',
        statement='Test decision',
        embedding=embedding
    )
    db.add(decision)
    db.commit()

    # Verify embedding stored
    stored = db.query(Decision).filter_by(id=decision.id).first()
    assert stored.embedding is not None
    assert len(stored.embedding) == 384

def test_cosine_similarity_query():
    """Test vector similarity query works."""
    db = Session()

    # Insert test decisions with embeddings
    query_vector = np.random.rand(384).tolist()
    similar_vector = query_vector + np.random.rand(384).tolist() * 0.01  # Very similar
    different_vector = np.random.rand(384).tolist()  # Different

    d1 = Decision(statement='Similar', embedding=similar_vector)
    d2 = Decision(statement='Different', embedding=different_vector)
    db.add_all([d1, d2])
    db.commit()

    # Query by similarity
    sql = text("""
        SELECT id, statement,
               1 - (embedding <=> :query_vector::vector) as similarity
        FROM decisions
        WHERE embedding IS NOT NULL
        ORDER BY embedding <=> :query_vector::vector
        LIMIT 5
    """)
    results = db.execute(sql, {'query_vector': query_vector}).fetchall()

    assert len(results) > 0
    # First result should be the similar one
    assert results[0][1] == 'Similar'
    assert results[0][2] > 0.9  # High similarity

def test_index_exists():
    """Test IVFFLAT index is created."""
    with engine.connect() as conn:
        result = conn.execute(text("""
            SELECT indexname
            FROM pg_indexes
            WHERE tablename='decisions'
            AND indexname='idx_decisions_embedding_cosine'
        """))
        # Note: Index created in Story 2.3 after data populated
        # This test will pass after Story 2.3
        pass
```

### Integration Test

```python
def test_vector_search_performance():
    """Test vector search performance with 1000 decisions."""
    import time
    db = Session()

    # Insert 1000 decisions with random embeddings
    decisions = []
    for i in range(1000):
        d = Decision(
            statement=f'Decision {i}',
            embedding=np.random.rand(384).tolist()
        )
        decisions.append(d)
    db.bulk_save_objects(decisions)
    db.commit()

    # Measure query time
    query_vector = np.random.rand(384).tolist()
    start = time.time()

    sql = text("""
        SELECT id, 1 - (embedding <=> :qv::vector) as similarity
        FROM decisions
        WHERE embedding IS NOT NULL
        ORDER BY embedding <=> :qv::vector
        LIMIT 10
    """)
    results = db.execute(sql, {'qv': query_vector}).fetchall()

    duration = time.time() - start
    assert duration < 0.5  # <500ms for 1000 decisions
    assert len(results) == 10
```

---

## Change Log

| Date | Change |
|------|--------|
| 2026-02-08 | Created story |

---

**Related Stories:** 2.1 (Sentence-transformers), 2.3 (Embedding pipeline)
**Blocked By:** 1.1 (database schema must exist)
**Blocks:** 2.3 (needs vector column to store embeddings), 2.4 (needs vector column for search)
