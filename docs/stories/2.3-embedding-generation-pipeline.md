# Story 2.3: Embedding Generation Pipeline

**Story ID:** 2.3
**Assigned to:** @dev
**Sprint:** Sprint 3 (Week 5)
**Status:** Draft
**Estimation:** 5 story points (2 days)

---

## Summary

Integrate embedding generation into the decision extraction pipeline. After each decision is extracted from a transcript, automatically generate a 384-dimensional embedding and store it in the database. This enables semantic search functionality.

---

## Acceptance Criteria

- [ ] Embedding generated for every new decision automatically
- [ ] Input text: Concatenation of `statement + why + impacts`
- [ ] Output: 384-dimensional vector stored in `decisions.embedding` column
- [ ] Batch processing: Multiple decisions embedded efficiently
- [ ] Performance: <100ms per decision (single), <3s for 50 decisions (batch)
- [ ] Error handling:
  - [ ] Empty text handled gracefully (log warning, skip embedding)
  - [ ] Embedding service failure logged and retried
  - [ ] Decision saved even if embedding fails (embedding=NULL)
- [ ] Idempotent: Re-running extraction doesn't duplicate embeddings
- [ ] Monitoring: Log embedding generation time metrics
- [ ] Tests passing: `pytest tests/unit/test_embedding_pipeline.py` (80%+ coverage)

---

## Tasks

### Task 1: Integrate EmbeddingService into Decision Extraction (0.5 days)

1. **Import embedding service**
   - Add `from app.utils.embeddings import EmbeddingService` to extraction module
   - Initialize singleton: `embedder = EmbeddingService()`
   - Verify model loads on startup

2. **Create embedding generation function**
   ```python
   def generate_decision_embedding(decision: Decision) -> List[float]:
       """Generate embedding for decision."""
       text = f"{decision.statement} {decision.why}"
       if decision.impacts:
           impact_text = " ".join([i.get('change', '') for i in decision.impacts])
           text = f"{text} {impact_text}"

       return embedder.embed_text(text)
   ```

3. **Add to extraction flow**
   - After decision extracted → generate embedding
   - Store embedding in `decision.embedding` field
   - Commit to database

### Task 2: Implement Batch Embedding for Multi-Decision Transcripts (0.75 days)

1. **Modify extraction pipeline**
   - Extract all decisions first (existing logic)
   - Collect all decision texts in list
   - Call `embedder.embed_batch(texts)`
   - Assign embeddings back to decisions

2. **Batch processing logic**
   ```python
   decisions = extract_decisions_from_transcript(transcript)

   # Prepare texts
   texts = []
   for d in decisions:
       text = f"{d.statement} {d.why}"
       if d.impacts:
           impact_text = " ".join([i.get('change', '') for i in d.impacts])
           text = f"{text} {impact_text}"
       texts.append(text)

   # Batch embed
   embeddings = embedder.embed_batch(texts, batch_size=32)

   # Assign to decisions
   for d, emb in zip(decisions, embeddings):
       d.embedding = emb

   db.add_all(decisions)
   db.commit()
   ```

3. **Test batch performance**
   - Test with 10, 50, 100 decisions
   - Verify faster than individual embeddings
   - Measure latency

### Task 3: Add Error Handling and Retry Logic (0.5 days)

1. **Handle embedding failures gracefully**
   ```python
   try:
       embedding = embedder.embed_text(text)
   except ValueError as e:
       logger.warning(f"Empty text for decision {decision.id}: {e}")
       embedding = None
   except Exception as e:
       logger.error(f"Embedding failed for decision {decision.id}: {e}")
       embedding = None

   decision.embedding = embedding
   db.add(decision)
   db.commit()  # Save decision even if embedding failed
   ```

2. **Add retry logic**
   - Use `tenacity` library for retries
   - Max 3 retries with exponential backoff
   - Log retry attempts

3. **Idempotency check**
   - Before generating: Check if `decision.embedding IS NOT NULL`
   - Skip if already exists
   - Allow force re-generation via CLI flag

### Task 4: Add Monitoring and Metrics (0.25 days)

1. **Log embedding metrics**
   ```python
   import time

   start = time.time()
   embeddings = embedder.embed_batch(texts)
   duration = time.time() - start

   logger.info(f"Generated {len(embeddings)} embeddings in {duration:.2f}s")
   logger.info(f"Avg latency: {duration / len(embeddings) * 1000:.0f}ms per decision")
   ```

2. **Track success/failure rates**
   - Count successful embeddings
   - Count failures
   - Log summary after each transcript

3. **Add health check**
   - Endpoint: `GET /health/embeddings`
   - Test if model loads and can generate embedding
   - Return status and latency

### Task 5: Write Tests (0.5 days)

1. **Create test file: `tests/unit/test_embedding_pipeline.py`**
   ```python
   @pytest.mark.asyncio
   async def test_embedding_generated_for_decision():
       """Test embedding generated during extraction."""
       transcript = create_test_transcript()
       decisions = await extract_and_embed_decisions(transcript)

       assert len(decisions) > 0
       for d in decisions:
           assert d.embedding is not None
           assert len(d.embedding) == 384

   @pytest.mark.asyncio
   async def test_batch_embedding_performance():
       """Test batch is faster than sequential."""
       decisions = [create_test_decision() for _ in range(50)]

       start = time.time()
       embeddings = embed_decisions_batch(decisions)
       batch_time = time.time() - start

       assert batch_time < 5.0  # <5s for 50 decisions

   @pytest.mark.asyncio
   async def test_embedding_failure_handling():
       """Test decision saved even if embedding fails."""
       decision = create_test_decision()
       decision.statement = ""  # Will fail embedding

       saved_decision = await save_decision_with_embedding(decision)
       assert saved_decision.id is not None
       assert saved_decision.embedding is None  # Failed, but decision saved
   ```

2. **Run tests**
   - `pytest tests/unit/test_embedding_pipeline.py --cov`
   - Target: 80%+ coverage
   - All tests passing

---

## Dev Notes

### Integration Points

**Where embeddings are generated:**
1. **Webhook handler** → Transcript received → Extract decisions → Generate embeddings
2. **Batch processing** → Backfill historical transcripts → Generate embeddings
3. **Manual API** → POST /decisions → Generate embedding for new decision

**Pipeline flow:**
```
Transcript Received
  ↓
Extract Decisions (LangGraph agent)
  ↓
Generate Embeddings (batch)
  ↓
Store in Database
  ↓
Ready for Semantic Search
```

### Implementation Code

```python
# app/services/extraction.py
from app.utils.embeddings import EmbeddingService
import logging
import time
from typing import List
from tenacity import retry, stop_after_attempt, wait_exponential

logger = logging.getLogger(__name__)
embedder = EmbeddingService()

@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=2, max=10))
def generate_embedding_with_retry(text: str) -> List[float]:
    """Generate embedding with retry logic."""
    return embedder.embed_text(text)

def prepare_decision_text(decision: dict) -> str:
    """Prepare text for embedding from decision fields."""
    parts = [
        decision.get('statement', ''),
        decision.get('why', '')
    ]

    # Add impacts
    if decision.get('impacts'):
        impacts_text = " ".join([i.get('change', '') for i in decision['impacts']])
        parts.append(impacts_text)

    return " ".join(parts).strip()

async def extract_and_embed_decisions(transcript: Transcript) -> List[Decision]:
    """Extract decisions from transcript and generate embeddings."""

    # Step 1: Extract decisions (existing LangGraph logic)
    logger.info(f"Extracting decisions from transcript {transcript.id}")
    decisions = await extract_decisions(transcript)
    logger.info(f"Extracted {len(decisions)} decisions")

    if not decisions:
        return []

    # Step 2: Prepare texts for batch embedding
    texts = [prepare_decision_text(d.__dict__) for d in decisions]

    # Step 3: Generate embeddings (batch)
    start = time.time()
    try:
        embeddings = embedder.embed_batch(texts, batch_size=32)
        duration = time.time() - start

        logger.info(f"Generated {len(embeddings)} embeddings in {duration:.2f}s")
        logger.info(f"Avg: {duration / len(embeddings) * 1000:.0f}ms per decision")

        # Step 4: Assign embeddings to decisions
        for decision, embedding in zip(decisions, embeddings):
            decision.embedding = embedding

    except Exception as e:
        logger.error(f"Batch embedding failed: {e}")
        # Fallback: Try individual embeddings
        for i, decision in enumerate(decisions):
            try:
                decision.embedding = generate_embedding_with_retry(texts[i])
            except Exception as ex:
                logger.error(f"Failed to embed decision {i}: {ex}")
                decision.embedding = None

    # Step 5: Save to database
    db.add_all(decisions)
    db.commit()

    success_count = sum(1 for d in decisions if d.embedding is not None)
    logger.info(f"Saved {success_count}/{len(decisions)} decisions with embeddings")

    return decisions
```

### Performance Benchmarks

| Operation | Target | Notes |
|-----------|--------|-------|
| Single embedding | <100ms | MiniLM fast model |
| Batch (50 decisions) | <3s | ~60ms per decision |
| Full transcript (60 decisions) | <4s | Extraction + embedding |
| Database save | <500ms | Bulk insert |

### Error Scenarios

| Scenario | Handling |
|----------|----------|
| Empty text | Log warning, set embedding=NULL |
| Model unavailable | Retry 3x, then save without embedding |
| Database error | Rollback transaction, retry entire batch |
| Timeout | Fallback to sequential processing |

---

## File List

**Modified/Created:**
- `app/services/extraction.py` (modify) - Add embedding generation to extraction flow
- `app/utils/embeddings.py` (existing) - Use existing EmbeddingService
- `tests/unit/test_embedding_pipeline.py` (new) - Pipeline integration tests
- `app/api/health.py` (modify) - Add embedding health check endpoint

---

## Testing Strategy

### Unit Tests (`tests/unit/test_embedding_pipeline.py`)

```python
import pytest
import time
from app.services.extraction import extract_and_embed_decisions, prepare_decision_text
from app.database.models import Transcript, Decision

@pytest.mark.asyncio
async def test_embedding_integration():
    """Test full extraction and embedding pipeline."""
    transcript = Transcript(
        project_id='test-project',
        transcript_text='CARLOS: We changed from concrete to steel...',
        meeting_type='client',
        participants=[{'name': 'Carlos'}]
    )

    decisions = await extract_and_embed_decisions(transcript)

    assert len(decisions) > 0
    assert decisions[0].embedding is not None
    assert len(decisions[0].embedding) == 384

@pytest.mark.asyncio
async def test_prepare_decision_text():
    """Test decision text preparation for embedding."""
    decision = {
        'statement': 'Changed material to steel',
        'why': 'Better seismic performance',
        'impacts': [
            {'type': 'timeline', 'change': '+2 weeks'},
            {'type': 'budget', 'change': '+$50K'}
        ]
    }

    text = prepare_decision_text(decision)

    assert 'Changed material to steel' in text
    assert 'Better seismic performance' in text
    assert '+2 weeks' in text
    assert '+$50K' in text

@pytest.mark.asyncio
async def test_batch_embedding_faster_than_sequential():
    """Test batch embedding performance."""
    decisions = [Decision(
        statement=f'Decision {i}',
        why='Some reasoning'
    ) for i in range(50)]

    start = time.time()
    decisions_with_embeddings = await extract_and_embed_decisions_batch(decisions)
    batch_time = time.time() - start

    assert batch_time < 5.0  # <5s for 50 decisions
    assert all(d.embedding is not None for d in decisions_with_embeddings)

@pytest.mark.asyncio
async def test_embedding_failure_doesnt_block_save():
    """Test decision saved even if embedding fails."""
    decision = Decision(
        statement='',  # Empty statement will fail
        why='Some reason'
    )

    with pytest.raises(ValueError):
        embedder.embed_text('')  # Verify it fails

    # But pipeline should handle it
    decisions = await extract_and_embed_decisions([decision])
    assert len(decisions) == 1
    assert decisions[0].id is not None
    assert decisions[0].embedding is None

@pytest.mark.asyncio
async def test_idempotent_embedding_generation():
    """Test re-running doesn't regenerate embeddings."""
    decision = Decision(
        statement='Test decision',
        why='Reasoning',
        embedding=[0.5] * 384  # Already has embedding
    )

    original_embedding = decision.embedding.copy()

    # Re-run pipeline
    await extract_and_embed_decisions([decision])

    # Embedding should be unchanged
    assert decision.embedding == original_embedding
```

### Integration Test

```python
@pytest.mark.integration
@pytest.mark.asyncio
async def test_end_to_end_extraction_with_embeddings(test_db):
    """Test full flow: Transcript → Decisions → Embeddings → Database."""
    # Create test transcript
    transcript = Transcript(
        project_id='test-project',
        meeting_type='client',
        participants=[{'name': 'Carlos', 'role': 'engineer'}],
        transcript_text='''
        CARLOS: We need to change the foundation depth from 2m to 3m.
        MARIA: Agreed, the soil analysis shows we need deeper foundations.
        CARLOS: This will add 2 weeks to the timeline and cost $50K more.
        '''
    )
    test_db.add(transcript)
    test_db.commit()

    # Run extraction and embedding
    decisions = await extract_and_embed_decisions(transcript)

    # Verify results
    assert len(decisions) > 0

    # Verify decisions saved to database
    stored = test_db.query(Decision).filter_by(transcript_id=transcript.id).all()
    assert len(stored) == len(decisions)

    # Verify embeddings
    for d in stored:
        assert d.embedding is not None
        assert len(d.embedding) == 384
        assert d.transcript_id == transcript.id
```

### Coverage Target

- Minimum: 80%
- Target: 90%+
- Run: `pytest tests/unit/test_embedding_pipeline.py --cov=app.services.extraction --cov-report=html`

---

## Change Log

| Date | Change |
|------|--------|
| 2026-02-08 | Created story |

---

**Related Stories:** 2.1 (Sentence-transformers), 2.2 (pgvector), 2.4 (Semantic search)
**Blocked By:** 2.1 (needs embedding service)
**Blocks:** 2.4 (semantic search needs embeddings in DB)
