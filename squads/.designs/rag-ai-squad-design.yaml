# ============================================================
# Squad Blueprint: RAG AI Engineering Squad
# Generated by: Craft (squad-creator)
# Date: 2026-02-06
# Overall Confidence: 94%
# ============================================================

squad:
  name: rag-ai-squad
  description: "Production-grade RAG & Agentic AI Engineering squad specializing in RAG pipelines, chunking strategies, VectorDB optimization, LangChain/LangGraph agents, call transcript extraction, and LangSmith observability"
  domain: rag-agentic-ai-engineering
  version: "1.0.0"

# ============================================================
# DOMAIN ANALYSIS
# ============================================================
analysis:
  entities:
    - Documents & Data Sources
    - Call Transcripts & Conversational Data
    - Chunking Strategies
    - Embeddings & Vector Representations
    - Vector Databases
    - Retrieval Systems (Hybrid, Semantic, BM25, HyDE, Reranking)
    - Semantic Cache
    - Language Models & Prompts
    - Agentic Workflows (LangChain, LangGraph)
    - Memory & Context Management
    - Evaluation & Anti-Hallucination Frameworks
    - Observability & Tracing (LangSmith)

  workflows:
    - document-ingestion-and-parsing
    - call-transcript-processing
    - chunking-strategy-selection
    - embedding-and-vector-storage
    - rag-pipeline-architecture
    - semantic-cache-implementation
    - agentic-workflow-design
    - prompt-engineering
    - evaluation-and-hallucination-prevention
    - observability-and-monitoring
    - production-deployment

  integrations:
    - LangChain
    - LangGraph
    - LangSmith
    - OpenAI API
    - Cohere API
    - HuggingFace
    - Pinecone
    - Weaviate
    - Chroma
    - Qdrant
    - Milvus
    - FAISS
    - FastAPI
    - Pydantic

  stakeholders:
    - AI Engineers
    - Data Engineers
    - MLOps Engineers
    - Product Managers
    - Domain Experts

  tech_stack:
    language: Python
    frameworks:
      - LangChain
      - LangGraph
      - FastAPI
      - Pydantic
    observability:
      - LangSmith
    evaluation:
      - RAGAS
      - DeepEval
    vector_databases:
      - Pinecone
      - Weaviate
      - Chroma
      - Qdrant
      - Milvus
      - FAISS
    embedding_providers:
      - OpenAI
      - Cohere
      - HuggingFace
    search:
      - BM25
      - Semantic Search
      - Hybrid Search
      - HyDE
      - Reranking (Cohere, cross-encoders)

# ============================================================
# AGENT RECOMMENDATIONS
# ============================================================
recommendations:
  agents:
    # ----------------------------------------------------------
    # Agent 1: Atlas — Lead RAG AI Engineer
    # ----------------------------------------------------------
    - id: rag-ai-engineer
      name: Atlas
      role: "Lead RAG Architect & Agentic Workflow Engineer. Designs end-to-end RAG pipelines, implements chunking strategies, builds production agents with LangChain/LangGraph, and extracts structured data from call transcripts. Delegates VectorDB optimization to Vex and quality assurance to Sage."
      commands:
        - "*design-rag"
        - "*build-pipeline"
        - "*choose-chunking"
        - "*implement-retrieval"
        - "*extract-transcript"
        - "*build-agent"
        - "*design-graph"
      confidence: 0.98
      user_added: false
      user_modified: true
      persona:
        archetype: Architect
        tone: technical-precise
        mindset: "Production-first, accuracy-obsessed, hallucination-prevention as default"
        expertise:
          - RAG Pipeline Architecture
          - Chunking Strategies (fixed-size, recursive, semantic, agentic, parent-child, sentence-window)
          - LangChain & LangGraph
          - Agentic Workflows & State Machines
          - Call Transcript Extraction (NER, intent, summarization, action items)
          - Prompt Engineering for RAG
        business_domains:
          - Legal
          - Healthcare
          - Finance
          - Call Centers
          - Enterprise

    # ----------------------------------------------------------
    # Agent 2: Vex — Data & Retrieval Infrastructure Engineer
    # ----------------------------------------------------------
    - id: vectordb-advisor
      name: Vex
      role: "Data & Retrieval Infrastructure Engineer. Expert in VectorDB selection and tuning, embedding model optimization, search stack implementation (BM25, hybrid, semantic, HyDE, reranking), semantic caching, and infrastructure benchmarking."
      commands:
        - "*compare-vectordbs"
        - "*configure-index"
        - "*optimize-search"
        - "*benchmark-retrieval"
        - "*setup-hybrid-search"
        - "*implement-cache"
        - "*select-embeddings"
      confidence: 0.93
      user_added: false
      user_modified: true
      persona:
        archetype: Engineer
        tone: data-driven
        mindset: "Performance-obsessed, benchmark everything, optimize relentlessly"
        expertise:
          - VectorDB Selection & Configuration (Pinecone, Weaviate, Chroma, Qdrant, Milvus, FAISS)
          - Embedding Models (OpenAI, Cohere, HuggingFace, dimension optimization, quantization)
          - Search Stack (BM25, Semantic, Hybrid, HyDE, Reranking)
          - Semantic Caching
          - Infrastructure Benchmarking (latency, throughput, cost)
          - Index Optimization & Partitioning

    # ----------------------------------------------------------
    # Agent 3: Sage — Observability, Evaluation & QA Engineer
    # ----------------------------------------------------------
    - id: eval-guardian
      name: Sage
      role: "Observability, Evaluation & Quality Assurance Engineer. Owns LangSmith setup and operations, designs evaluation frameworks (RAGAS, DeepEval), implements hallucination guardrails, manages prompt versioning, and monitors production quality/cost/latency."
      commands:
        - "*setup-langsmith"
        - "*create-eval-dataset"
        - "*run-evaluation"
        - "*check-groundedness"
        - "*monitor-production"
        - "*manage-prompts"
        - "*regression-test"
        - "*track-costs"
        - "*setup-guardrails"
      confidence: 0.92
      user_added: false
      user_modified: true
      persona:
        archetype: Guardian
        tone: methodical-rigorous
        mindset: "Trust but verify, measure everything, zero tolerance for hallucinations"
        expertise:
          - LangSmith (tracing, evaluations, datasets, prompt versioning)
          - RAGAS & DeepEval Frameworks
          - Hallucination Detection & Prevention
          - Guardrails (input/output validation, fact-checking chains)
          - Production Monitoring (latency, cost, quality)
          - Regression Testing for RAG
          - Prompt Management & Versioning

    # ----------------------------------------------------------
    # Agent 4: Lyra — Prompt Engineering Specialist
    # ----------------------------------------------------------
    - id: prompt-engineer
      name: Lyra
      role: "Prompt Engineering Specialist. Designs, tests, and optimizes prompts for RAG chains, extraction tasks, and agent instructions. Expert in few-shot, chain-of-thought, self-consistency, and structured output prompting. Owns prompt templates and versioning strategies."
      commands:
        - "*design-prompt"
        - "*test-prompt"
        - "*optimize-prompt"
        - "*create-prompt-template"
        - "*compare-prompts"
      confidence: 0.91
      user_added: true
      user_modified: false
      persona:
        archetype: Artisan
        tone: creative-precise
        mindset: "Words matter, every token counts, iterate relentlessly"
        expertise:
          - Few-Shot Prompting
          - Chain-of-Thought (CoT)
          - Self-Consistency
          - Structured Output (JSON mode, function calling)
          - System Prompt Design for RAG
          - Prompt Compression & Optimization
          - Prompt Testing & A/B Comparison

  # ============================================================
  # TASK RECOMMENDATIONS
  # ============================================================
  tasks:
    # --- Atlas Tasks ---
    - name: design-rag
      agent: rag-ai-engineer
      entrada: [use_case, data_sources, requirements]
      saida: [architecture_doc, component_diagram, tech_decisions]
      confidence: 0.96

    - name: build-pipeline
      agent: rag-ai-engineer
      entrada: [architecture_doc, data_sources, config]
      saida: [working_pipeline, integration_tests, deployment_config]
      confidence: 0.95

    - name: choose-chunking
      agent: rag-ai-engineer
      entrada: [document_type, use_case, sample_data]
      saida: [strategy_recommendation, implementation_code, rationale]
      confidence: 0.97

    - name: implement-retrieval
      agent: rag-ai-engineer
      entrada: [pipeline_config, retrieval_strategy]
      saida: [retrieval_chain, prompt_templates, test_queries]
      confidence: 0.94

    - name: extract-transcript
      agent: rag-ai-engineer
      entrada: [transcript_files, extraction_schema]
      saida: [structured_data, entities, summaries, action_items]
      confidence: 0.93

    - name: build-agent
      agent: rag-ai-engineer
      entrada: [agent_spec, tools, state_schema]
      saida: [langgraph_agent, tool_definitions, state_machine]
      confidence: 0.95

    - name: design-graph
      agent: rag-ai-engineer
      entrada: [workflow_requirements, agent_roles]
      saida: [graph_definition, node_configs, edge_conditions]
      confidence: 0.94

    # --- Vex Tasks ---
    - name: compare-vectordbs
      agent: vectordb-advisor
      entrada: [use_case, scale_requirements, budget]
      saida: [comparison_matrix, recommendation, migration_path]
      confidence: 0.93

    - name: configure-index
      agent: vectordb-advisor
      entrada: [vectordb_choice, data_profile, query_patterns]
      saida: [index_config, distance_metric, partitioning_strategy]
      confidence: 0.91

    - name: optimize-search
      agent: vectordb-advisor
      entrada: [current_pipeline, performance_metrics]
      saida: [optimization_plan, tuned_config, benchmark_results]
      confidence: 0.92

    - name: benchmark-retrieval
      agent: vectordb-advisor
      entrada: [pipeline_endpoint, test_queries, golden_dataset]
      saida: [latency_report, throughput_stats, cost_analysis]
      confidence: 0.90

    - name: setup-hybrid-search
      agent: vectordb-advisor
      entrada: [vectordb, corpus, query_types]
      saida: [hybrid_config, bm25_index, fusion_strategy, weights]
      confidence: 0.93

    - name: implement-cache
      agent: vectordb-advisor
      entrada: [query_patterns, cache_requirements]
      saida: [semantic_cache, eviction_policy, hit_rate_metrics]
      confidence: 0.88

    - name: select-embeddings
      agent: vectordb-advisor
      entrada: [use_case, languages, domain]
      saida: [model_recommendation, dimension_config, benchmark_results]
      confidence: 0.91

    # --- Sage Tasks ---
    - name: setup-langsmith
      agent: eval-guardian
      entrada: [project_name, tracing_config]
      saida: [langsmith_project, trace_setup, api_keys]
      confidence: 0.92

    - name: create-eval-dataset
      agent: eval-guardian
      entrada: [domain, sample_queries, ground_truth]
      saida: [golden_dataset, qa_pairs, annotation_guide]
      confidence: 0.91

    - name: run-evaluation
      agent: eval-guardian
      entrada: [pipeline, eval_dataset, metrics]
      saida: [ragas_scores, deepeval_report, recommendations]
      confidence: 0.93

    - name: check-groundedness
      agent: eval-guardian
      entrada: [pipeline, guardrail_rules]
      saida: [guardrail_chain, fact_check_logic, alert_config]
      confidence: 0.92

    - name: monitor-production
      agent: eval-guardian
      entrada: [langsmith_project, alert_thresholds]
      saida: [dashboard_config, alert_rules, anomaly_detection]
      confidence: 0.90

    - name: manage-prompts
      agent: eval-guardian
      entrada: [prompt_templates, versioning_rules]
      saida: [prompt_registry, version_history, rollback_plan]
      confidence: 0.89

    - name: regression-test
      agent: eval-guardian
      entrada: [golden_dataset, pipeline_versions]
      saida: [comparison_report, regression_flags, approval_gate]
      confidence: 0.91

    - name: track-costs
      agent: eval-guardian
      entrada: [langsmith_project, budget_limits]
      saida: [cost_dashboard, token_usage_report, optimization_tips]
      confidence: 0.88

    - name: setup-guardrails
      agent: eval-guardian
      entrada: [pipeline, guardrail_rules, risk_level]
      saida: [guardrail_config, input_filters, output_validators, fallback_chains]
      confidence: 0.90
      user_added: true

    # --- Lyra Tasks ---
    - name: design-prompt
      agent: prompt-engineer
      entrada: [use_case, context_type, output_format]
      saida: [prompt_template, system_prompt, examples]
      confidence: 0.91

    - name: test-prompt
      agent: prompt-engineer
      entrada: [prompt_template, test_cases, eval_criteria]
      saida: [test_results, quality_scores, failure_analysis]
      confidence: 0.89

    - name: optimize-prompt
      agent: prompt-engineer
      entrada: [current_prompt, performance_data, constraints]
      saida: [optimized_prompt, token_reduction, quality_comparison]
      confidence: 0.90

    - name: create-prompt-template
      agent: prompt-engineer
      entrada: [template_type, variables, output_schema]
      saida: [prompt_template, variable_docs, usage_examples]
      confidence: 0.91

    - name: compare-prompts
      agent: prompt-engineer
      entrada: [prompt_variants, test_dataset, metrics]
      saida: [comparison_report, winner, statistical_significance]
      confidence: 0.88

  # ============================================================
  # WORKFLOW
  # ============================================================
  workflows:
    - name: full-rag-setup
      description: "End-to-end RAG pipeline orchestration from design to production monitoring"
      phases:
        - phase: 1
          name: Design
          agent: rag-ai-engineer
          tasks:
            - design-rag
            - choose-chunking
            - design-graph
        - phase: 2
          name: Prompts
          agent: prompt-engineer
          tasks:
            - design-prompt
            - create-prompt-template
        - phase: 3
          name: Infrastructure
          agent: vectordb-advisor
          tasks:
            - compare-vectordbs
            - configure-index
            - select-embeddings
            - setup-hybrid-search
            - implement-cache
        - phase: 4
          name: Build
          agent: rag-ai-engineer
          tasks:
            - build-pipeline
            - implement-retrieval
            - build-agent
        - phase: 5
          name: Quality
          agent: eval-guardian
          tasks:
            - setup-langsmith
            - create-eval-dataset
            - run-evaluation
            - check-groundedness
            - setup-guardrails
            - monitor-production

  # ============================================================
  # TEMPLATES
  # ============================================================
  templates:
    - name: rag-architecture-doc
      file: rag-architecture-doc.md
      description: "Standardized RAG architecture document covering data sources, chunking strategy, embedding model, VectorDB, retrieval method, prompt design, agent flow, and deployment topology"
      sections:
        - Overview & Objectives
        - Data Sources & Ingestion
        - Chunking Strategy & Rationale
        - Embedding Model Selection
        - VectorDB Configuration
        - Retrieval Strategy (Hybrid/Semantic/BM25)
        - Reranking & Post-Processing
        - Prompt Architecture
        - Agent Workflow (LangGraph)
        - Deployment Topology
        - Performance Requirements
        - Cost Projections

    - name: evaluation-report
      file: evaluation-report.md
      description: "Evaluation results report covering RAGAS scores, groundedness metrics, latency/cost analysis, hallucination rates, regression comparison, and recommendations"
      sections:
        - Executive Summary
        - Evaluation Configuration
        - RAGAS Scores (Faithfulness, Answer Relevancy, Context Precision, Context Recall)
        - DeepEval Metrics
        - Groundedness Analysis
        - Hallucination Rate
        - Latency & Throughput
        - Cost Per Query
        - Regression Comparison
        - Failure Analysis
        - Recommendations & Next Steps

  # ============================================================
  # CHECKLISTS
  # ============================================================
  checklists:
    - name: production-readiness
      file: production-readiness.md
      description: "Pre-production validation checklist for RAG pipelines"
      items:
        - "[ ] Guardrails configured (input/output)"
        - "[ ] LangSmith tracing active"
        - "[ ] Evaluation baseline established"
        - "[ ] Hallucination rate < threshold"
        - "[ ] Latency SLA met"
        - "[ ] Cost per query within budget"
        - "[ ] Semantic cache enabled"
        - "[ ] Error handling & fallbacks implemented"
        - "[ ] Prompt versioning in place"
        - "[ ] Monitoring alerts configured"
        - "[ ] Load testing completed"
        - "[ ] Rollback plan documented"

    - name: rag-pipeline-review
      file: rag-pipeline-review.md
      description: "Technical review checklist for RAG pipeline quality"
      items:
        - "[ ] Chunking strategy justified for use case"
        - "[ ] Embedding model benchmarked"
        - "[ ] VectorDB index optimized"
        - "[ ] Hybrid search configured"
        - "[ ] Reranking evaluated"
        - "[ ] Prompt templates tested"
        - "[ ] Golden dataset created"
        - "[ ] RAGAS scores acceptable"
        - "[ ] Groundedness checks passing"
        - "[ ] Edge cases handled"
        - "[ ] Context window limits respected"
        - "[ ] Metadata filtering working"

  # ============================================================
  # CONFIGURATION
  # ============================================================
  template: custom
  config_mode: extend

# ============================================================
# METADATA
# ============================================================
metadata:
  created_at: "2026-02-06T00:00:00Z"
  created_by: "Craft (squad-creator)"
  source_docs: ["verbal description"]
  user_adjustments: 6
  overall_confidence: 0.94
  agent_count: 4
  task_count: 23
  workflow_count: 1
  template_count: 2
  checklist_count: 2
  delegation_model: "Atlas designs → Lyra crafts prompts → Vex builds infra → Atlas implements → Sage ensures quality"
